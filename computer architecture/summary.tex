\documentclass[a4paper]{ctexbook}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{ulem}
\usepackage{multirow}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{color}
\usepackage{float}
\definecolor{grey}{RGB}{90,90,90}
\usepackage{verbatim}
\newcommand{\li}{\uline{\hspace{0.5em}}}
\newcommand{\blank}[1]{(\emph{\underline{#1}})}
\CTEXsetup[format={\Large\bfseries}]{section}  


\begin{document}
\begin{titlepage}
  \thispagestyle{empty}
  \title{高级体系结构总结}
  \author{杨森}
  \maketitle
\end{titlepage}
\thispagestyle{empty}

\chapter{基础}
\setcounter{page}{1}
\section{名词解释/填空}
\begin{enumerate}
  \item (\emph{\underline{微处理器技术}})的发展带来了计算机设计的复兴,既强调(\emph{\underline{体系结构}})方面的创新,也重视技术改进的高效应用.(2006)
  \item Throughout this range in price and capabiity, the desktop market tends to be driven to optimize (\emph{\underline{price-performance}}).(2006)
  \item Power Consumption in Computer Systems Power consumption in modern systems is dependent on a variety of factors, including the chip \blank{clock frequency}, \blank{efficiency}, the disk drive speed, disk drive utilization, and \blank{DRAM}.(2013)
  \item 服务器的三个关键特征:(\emph{\underline{可用性}}),(\emph{\underline{可扩展性}}),(\emph{\underline{吞吐能力}}).(2006)
  \item 一个事件从启动到完成的时间,称为(\emph{\underline{响应时间}}),也称为(\emph{\underline{执行时间}})；仓库级计算机的操作人员可能关心的是(\emph{\underline{吞吐量}}),也就是给定时间内完成的总工作量.(2006)
  \item \textbf{计算机体系结构}:计算机系统结构是指\blank{传统机器程序员}看到的\blank{计算机属性},即\blank{概念性结构}和\blank{功能特性}.(2001、2005、2008、2013)
  \item 存储程序计算机(冯诺依曼结构)的特点是:机器以(\emph{\underline{运算器}})为中心；采用存储程序原理；存储器是按照(\emph{\underline{地址}})访问的、线性编址的空间；控制流由(\emph{\underline{指令流}})流产生；指令由操作码和地址码组成；数据以(\emph{\underline{二}})进制编码表示,采用二进制运算；由\blank{运算器},\blank{存储器},\blank{输入/输出设备},\blank{控制器}组成(2007、2009、2012、2015)
  \item 程序的局部性原理是指:程序总是趋向于使用最近使用过的(\emph{\underline{数据}})和(\emph{\underline{指令}}),程序执行时所访问的存储器地址不是随机分布的,而是相对簇集,包括(\emph{\underline{时间局部性}})和(\emph{\underline{空间局部性}}):(2008、2012、2015)
  \begin{enumerate}
    \item \textbf{时间局部性}:程序即将用到的信息很可能是目前正在使用的信息.(2002)
    \item \emph{空间局部性}:程序即将用到的信息很可能与目前正在使用的信息在空间上邻近.
  \end{enumerate}
  \item \textbf{软件兼容(Software Compatable)}:软件兼容是指一台计算机上的程序不加修改就可以搬到另一台计算机上正常运行.(2002)
  \item 所谓\emph{系列机}就是指具有相同的(\emph{\underline{体系结构}}),但具有不同(\emph{\underline{组成}})和(\emph{\underline{实现}})的一些列不同型号的机器.我们把不同厂家生产的具有相同体系结构的计算机称为(\emph{\underline{兼容机}}).(2008、2010、2013)
  \item \textbf{并行性(parallelism)}:并行性是指计算机系统在同一时刻或者同一时间间隔内运行多种运算或者操作,包括同时性和并发性两种含义,同时性是指两个或两个以上的事件在同一时刻发生,并发性是指两个或两个以上的事件在同一时间间隔内发生.(2002)
  \item \emph{大概率事件优先原则}：对于大概率事件，赋予它优先的处理权和资源使用权。
  \item \textbf{Amdahl定律}:当对一个系统中的某个部件进行改进后,所能获得的整个系统性能\blank{加速比},受限于该部件的\blank{执行时间}占总执行时间的\blank{百分比}.(2004、2010、2011、2014、2016)
  \item 器件发生故障的概率与\blank{时间}的关系可以使用\textbf{学习曲线}来说明。(2011)
  \item 我们把DRAM这种不供电数据丢失的存储器称为\blank{易失性}存储器，把磁盘这种不供电也能够保存数据的存储器称为\blank{非易失性}存储器。(2015)
  \item \emph{模拟(Simulation)}:用软件方法在一台现有计算机上实现另一台计算机的指令系统。
\end{enumerate}
\section{简答题}
\begin{enumerate}
  \item {\color{grey}简述存储程序计算机的特点:(2002)
  
  机器以\emph{运算器}为中心；采用存储程序原理；存储器是按照\emph{地址}访问的、线性编址的空间；控制流由\emph{指令流}流产生；指令由操作码和地址码组成；数据以\emph{二}进制编码表示,采用二进制运算；由\emph{运算器},\emph{存储器},\emph{输入/输出设备},\emph{控制器}组成。}

  
\end{enumerate}

\newpage
\chapter{指令系统}
\section{名词解释/填空}
\begin{enumerate}
  \item 设计指令系统包括\blank{寻址方式设计}，\blank{指令集功能设计}，\blank{操作数表示和数据类型}，\blank{指令系统编码设计}。(2011、2016)
  \item \textbf{RISC}含义是\blank{精简指令集计算机},\textbf{CISC}含义是\blank{复杂指令集计算机}；把指令集设计成只包含那些频率高的少量指令，并提供一些必要的指令以支持\blank{操作系统}和\blank{高级语言}，按照这个原则设计的计算机称为精简指令集计算机。(2008、2015)
  \item \textbf{寄存器-寄存器型(Load/Store型)}指令结构:操作数都来自\blank{通用寄存器组}。(2001、2003)
  \item 指令系统的基本要求:
  \begin{enumerate}
    \item \emph{完整性}:在有限可用的存储空间内,对于任何可解的问题,编制计算程序时,指令系统提供的功能足够使用.
    \item \textbf{规整性}:指令系统的规整性主要包括对称性和均匀性,对称性是指所有与指令系统有关的存储单元的使用、操作码的设置等都是对称的；均匀性是指对于各种不同的操作数类型、字长、操作种类和数据存储单元,指令的设置都要同等对待.(2001、2004)
    \item \textbf{正交性}:指令中各个不同含义的字段,如操作类型、数据类型、寻址方式字段等,在编码时应该互不相关、相互独立.(2002)
    \item \emph{高效率}:指令的执行速度快、使用频率高。
  \end{enumerate}
\end{enumerate}
\section{简答题}
\begin{enumerate}
  \item {\color{grey}\emph{CISC结构计算机的缺点和RISC结构计算机的设计原则}:(2004)
  
    CISC是复杂指令集计算机，缺点主要有以下几点：
    \begin{itemize}
      \item 各种指令的使用频率相差悬殊，许多指令很少用到。
      \item 指令系统庞大，指令条数很多，许多指令功能又很复杂，这使得控制器硬件变得非常复杂。
      \item 许多指令由于操作繁杂，其CPI值比较大，执行速度慢。
      \item 由于指令功能复杂，规整性不好，不利于利用流水线来提高性能。
    \end{itemize}
    
    RISC是精简指令集计算机，设计原则主要包括以下几点:
    \begin{itemize}
      \item 指令条数少、指令功能简单；
      \item 采用简单而统一的指令格式，减少寻址方式；
      \item 指令的执行在单周期内完成(采用流水线技术);
      \item 采用load-store结构，即只有load和store指令才能访问存储器，其它指令的操作都是在寄存器之间进行的；
      \item 大多数指令都采用硬连逻辑实现；
      \item 强调优化编译器的作用，为高级语言程序生成优化的代码；
      \item 充分利用流水技术来提高性能。
    \end{itemize}
  }
\end{enumerate}

\newpage
\chapter{流水线}
\section{名词解释/填空}
\begin{enumerate}
  \item 流水线分类：
  \begin{enumerate}
    \item \emph{部件级流水线(Arithmetic Pipeline)}:把处理机中的部件进行分段,再把这些分段相互连接而成.
    \item \emph{处理机级流水线}:又称指令流水线(Instruction Pipeline),把指令的执行过程按照流水方式进行处理,即把一条指令的执行过程分解为若干个子过程.
    \item \emph{系统级流水线}:又称为宏流水线(Macro Pipeline),把多个处理机串行连接起来,对同一数据流进行处理,每个处理机完成整个任务中的一部分.
    \item \emph{单功能流水线(Unifunction Pipeline)}:流水线各段之间连接固定不变,只能完成单一固定功能.
    \item \textbf{多功能流水线(Multifunction Pipeline)}:流水线各段之间可以进行不同的连接,以实现不同功能.(2004)
    \item \emph{静态流水线(Static Pipeline)}:同一时间内,多功能流水线的各段只能按照同一种功能的连接方式工作.
    \item \emph{动态流水线(Dynamic Pipeline)}:同一时间内,多功能流水线的各段可以按照不同的方式连接.
    \item \emph{线性流水线(Linear Pipeline)}:流水线各段串行连接、没有回馈.
    \item \emph{非线性流水线(Nonlinear Pipeline)}:各段除了有串行的连接外,还有反馈回路.
    \item \emph{顺序流水线(In-order Pipeline)}:流水线输出端任务流出顺序与输入端任务流入顺序完全相同.
    \item \emph{乱序流水线(Out-order Pipeline)}:流水线输出端任务流出顺序与输入端任务流入顺序可以不同.
  \end{enumerate}
  \item 对于采用指令流水线的处理器,其CPI公式为: CPI流水线 = 流水线理想CPI + (\emph{\underline{结构相关导致的停顿}}) + (\emph{\underline{数据相关导致的停顿}}) + (\emph{\underline{控制相关导致的停顿}}).(2005、2007、2013)
  \item 流水线的理想CPI是衡量流水线(\emph{\underline{最高}})性能的一个指标.(2006)
  \item \emph{冲突/冒险(Hazard)}：由于指令之间存在依赖关系，使得指令流中的下一条指令不能在指定的时钟周期开始执行。
  \item 相关分类
  \begin{enumerate}
    \item \textbf{结构相关}:当指令在同步重叠执行过程中,硬件资源满足不了指令重叠执行的要求,发生资源冲突.(2001、2002、2003)
    \item \textbf{数据相关(真相关)}:对于顺序指令i和j，指令i和j存在数据相关是指，指令j的\blank{操作数寄存器或存储单元}是指令i要写入的寄存器或者\blank{存储单元}。或者指令j与k数据相关，指令k与指令i数据相关，则指令j与指令i数据相关。(2006、2010)
    \item \emph{控制相关}:当流水线遇到分支指令和其它能够改变PC值的指令就会发生控制相关.
    \item \emph{名相关}：指令使用的寄存器或存储器称为名，如果两条指令使用相同的名，但是他们之间没有数据流，则称之为名相关。
    \begin{enumerate}
      \item \emph{输出相关}:如果指令j和指令i所写的名相同,则称指令i和j发生了输出相关。
      \item \textbf{反相关}:如果指令j的\blank{目标寄存器或存储单元}是指令i要\blank{访问}的\blank{寄存器}或\blank{存储单元}，则称指令i和指令j发生了反相关。(2011、2014、2016、2017)
    \end{enumerate}
  \end{enumerate}
  \item 解决流水线瓶颈的方法有\blank{细分瓶颈段}和\blank{瓶颈段重复设置}。
  \item \textbf{吞吐率(ThroughPut, TP)}:单位时间内流水线所完成的任务数量或者输出结果的数量.(2002)
  \item \textbf{定向(Forwarding, Bypassing)}:在某条指令产生一个计算结果之前，其它指令并不真正需要该计算结果，如果能够将该计算结果从其产生的地方直接送到其它指令需要它的地方，就可以避免因数据相关引起的停顿，这就是定向技术。(2003、2017)
  \item \textbf{分支延迟槽(Branch Delay Slot)}:存放分支指令的后继指令，无论分支指令成功与否，都会执行分支延迟槽中的指令。(2017)
  \item \emph{分支延迟(Branch Delay)}：由分支指令引起的延迟。
  \item \textbf{异常(Exception)}:异常也称为中断或错误，主要分为两类，一类会导致程序终止运行，另一类则要求在程序处理完异常后继续“透明”地执行原来程序。(2017)
  \item \emph{精确异常(precise exception)、非精确异常}:不精确异常是指，当指令i导致发生异常时，处理机的现场与严格按程序顺序执行时指令i的现场不同。如果发生异常时，处理机的现场与严格按照程序顺序执行时指令i是现场相同，就称为精确异常；如果流水线能够准确的判断出异常是由流水线的哪一条指令引发的，并可以正确的保留住这一条指令的现场，则称之为精确异常处理，否则就是非精确异常处理。
  \item \emph{流水线互锁(Pipeline Interlock)}：用于检测发现数据冲突，并是流水线停顿，直至冲突消失。
  \item \emph{分支取消机制(Canceling，Nullifying)}：分支指令隐含了预测的分支执行方向。当分支的实际执行方向和事先预测的一样时，执行分支延迟槽中的指令，否则就将该指令转化成空操作。
\end{enumerate}
\section{简答题}
\begin{enumerate}
  \item 降低流水线分支损失的方法：
  
  冻结(freze)或排空(flush)流水线，一旦在ID段检测到分支指令，就暂停后续指令的执行；预测分支失败；预测分支成功；延迟分支，从逻辑上延长分支指令的执行时间。
\end{enumerate}


\newpage
\chapter{向量处理机}
\section{名词解释/填空}
\begin{enumerate}
  \item \emph{通过时间}:第一个任务从进入流水线到流出结果的时间段.
  \item \emph{排空时间}:最后一个任务从进入流水线到流出结果的时间段.
  \item 流水线的\textbf{链接(pipeline chaining)}是将流水线计算机中多个(\emph{\underline{功能部件}})按照指令要求链接在一起,构成一个\blank{长流水线},减少各个功能部件流水线(\emph{\underline{加载/建立}})和\blank{排空}的时间,提高流水线\blank{执行的效率}；向量流水线的链接是在有\blank{数据(写后读)}相关的\blank{两}条指令之间,将产生数据的指令部件的\blank{结果}直接送到使用数据部件的\blank{输入}.(2007、2009、2010、2011、2013、2014、2016)
  \item 分段开采：当向量的长度大于向量寄存器的长度时，必须把长向量分成长度固定的段，然后循环分段处理，每一次循环只处理一个向量段。这种技术称为分段开采技术。
  
  分段开始的时间计算公式： $T_{all}=\lceil\frac{n}{MUL}\rceil\times(T_{start}+T_{loop})+mn$  ($MUL$表示向量寄存器长度，$m$表示编队数，$n$表示向量长度，$T_{start}=\text{通过时间}-1$,$T_{loop}$表示编队执行带来的开销)。     
\end{enumerate}
%%
\newpage
\chapter{指令级并行}
\section{名词解释/填空}
\begin{enumerate}
  \item \emph{数据级并行(Data-level Paralism)}:在数据并行中，不同机器有着整个模型的完全拷贝；每个机器只获得整个数据的不同部分，计算的结果通过某些方法结合起来。
  \item \emph{任务级并行(Task-level Paralism)}:每一个线程执行一个分配到的任务，而这些线程则被分配到该并行计算体系的各个计算节点中去。
  \item \emph{循环级并行(Loop-level Paralism)}:循环结构中不同迭代之间的并行性。
  \item \emph{线程级并行(Thread Level Paralism, TLP)}:在一种耦合硬件模型中开发数据级并行和任务级并行，这种模型允许线程之间进行交互。
  \item \emph{指令级并行(Instruction Level Paralism, ILP)}:当指令之间不存在\blank{相关}时，它们在流水线中是可以重叠起来并行执行的，这种指令序列中存在的潜在的并行性称为\blank{指令级并行}。(2015)
  \item \emph{循环展开(Loop Unrolling)}:展开循环体若干次，将循环级并行转化为指令级并行的技术。
  \item \textbf{基本块(Basic Block)}:一段连续的代码除了入口和出口,没有其它的分支指令和转入点,这称其为基本块.(2003)
  \item \emph{指令调度}:通过改变指令在程序中的位置，将相关指令之间的距离加大到不小于指令执行延迟的时钟周期数，这样就可以将相关指令转化为无关指令，指令调度受限于指令固有的指令级并行和功能部件的延迟。
  \item This potential overlap among instructions is called (\emph{\underline{instruction-level parallelism (ILP)}}) since the instructions can be evaluated in (\emph{\underline{parallel}})。(2006)
  \item \emph{静态调度(Static Scheduling)}:在编译期间而非程序执行过程中进行代码的\blank{调度和优化}。
  \item \textbf{动态调度(Dynamic Scheduling)}:在程序的执行过程中,依靠专门硬件对代码进行调度.(2004)
  \item \textbf{乱序流出(Out of order issue)}:程序中的\blank{指令}不是按照排列的顺序流出,而是当指令需要的资源条件得到满足时即\blank{流出}.(2001、2010)
  \item \emph{乱序执行(Out of order Execution)}:指令的执行顺序与程序顺序不同。
  \item \emph{乱序完成(Out of order completion)}:指令的完成顺序与程序顺序不同。
  \item \textbf{分支预测缓冲(Branch Prediction Buffer, BPB, BHT)}:仅使用一片存储区域,记录最近一次或几次的分支特征的历史,包括两个步骤,分支预测和预测位修改.(2004)
  \item \emph{分支目标缓冲(Branch Target Buffer, BTB)}:将分支成功的分支指令和它的分支目标地址都放到一个缓冲区中保存起来,缓冲区以分支指令的地址作为标识.
  \item 在前瞻执行(speculation)中,指令的流出过程是\blank{顺序}的,但结束过程的确认是\blank{顺序}的,再定序缓冲用于保存执行完毕但尚未顺序确认的指令.(2009)
  \item \textbf{再定序缓冲(ReOrder Buffer)}:指令前瞻执行时在确认阶段需要一套额外的硬件缓冲来保存那些执行完毕但未经确认的指令及其结果，这种硬件的缓冲称为再定序缓冲，ROB的每个项包括指令类型、目的地址、值域和就绪字段。(2001)
  \item \textbf{超标量技术(Superscalar)}:在每个时钟周期流出多条指令,但流出的指令的条数不固定，可以通过编译器静态调度，也可以通过记分牌或Tomasulo进行动态调度.(2003、2017)
  \item \emph{VLIW}：是一种多指令流出技术，采用多个独立的功能部件，将多条指令的操作组装成固定格式的指令包，形成一条非常长的指令。
  \item \emph{超流水}：处理器的每个功能部件进一步流水化，被分解成多个段，使得一个功能部件在同一周期能够处理多条指令。
  \item \textbf{全局代码调度(Globa code scheduling)}:把分支之前的指令调度到分支之后,或者把分支之后的指令调度到分支之前,称之为(\emph{\underline{全局}})代码调度,其目的是在保持代段\blank{数据}相关和\blank{控制}相关不变的前提下,将一段内部包含\blank{控制相关}的代码段压缩到尽可能最短。(2005、2017)
  \item \textbf{软流水}:\blank{循环重组技术},使得\blank{循环体}由原来不同循环中指令组成.是一种用于程序中\blank{循环结构}的指令\blank{重组}技术,又称为\blank{符号化循环展开}。(2002、2005、2007、2010)
  \item \emph{保留站(Reserve Station)}:保留站中保存已经流出并等待相应功能部件执行的指令，其内容包括操作码、操作数以及用于检测和解决冲突的信息。
  \item \emph{路径调度}：通过增加执行频率低的分支开销来简化代码调度。
  \item \emph{路径压缩(Trace Compaction)}:将路径中的操作尽可能提前，并将所有操作尽可能压缩成少量长指令，并尽量进行调度。
\end{enumerate}
\section{简答题}

\begin{enumerate}
  
  \item \emph{基于硬件前瞻执行的优缺点}：
  
  One of the significant advantages of speculation is its ability to uncover events that would otherwise stall the pipeline early, such as cache misses. This potential advantage, however, comes with a significant potential disadvantage. Speculation is not free. It takes time and energy, and the recovery of incorrect speculation further reduces performance. In addition, to support the higher instruction execution rate needed to benefit from speculation, the processor must have additional resources, which take silicon area and power. Finally, if speculation causes an exceptional event to occur, such as a cache or translation lookaside buffer (TLB) miss, the potential for significant performance loss increases, if that event would not have occurred without speculation. 
  
  前瞻执行结合了动态分支预测、控制结果尚未确定时前瞻执行后续指令、跨越基本快的动态调度的三种思想，能很好地解决控制相关的问题。前瞻执行允许指令乱序执行，但要求按程序顺序确认。前瞻执行能够实现精确异常，例如Cache不命中，当某条指令引起异常时，等待该指令到达ROB的头部再对该指令引起的异常进行处理，同时清除所有正在执行的指令。前瞻执行的最大缺点是所需硬件太复杂。除此之外，当前瞻执行预测错误进行恢复时会降低性能；如果前瞻执行导致异常事件，例如Cache不命中或TLB不命中，也会导致性能的下降。

  \item 处理器中指令的流出能力是有限的，主要受以下三个方面的影响：(2003)
  \begin{itemize}
    \item 程序所固有的指令级并行性。对于流水线处理器，需要有大量可并行执行的操作才能避免流水线出现停顿。
    \item 硬件实现上的困难。多流出的处理其需要大量的硬件资源。随着每个时钟周期流出指令数的增加，所需的硬件成正比例的增长。同时所需的存储器带宽和寄存器带宽也大大增加了。
    \item 超标量和超长指令字处理器固有的技术限制。超标量处理器无论采用记分牌技术还是Tomasulo技术都需要大量的硬件，VLIW处理器仅需要很少甚至不需要额外的硬件，因为这些工作全部由编译器完成。
  \end{itemize}

  \item \emph{五级流水线中分支目标缓冲的过程}：(2017)
  \begin{figure}[H]
    \centering
    \includegraphics[height=0.4\textwidth]{figures/BTB.png}
  \end{figure}
  
  \item 记分牌算法和Tomasulo算法的基本思想：
  \begin{enumerate}
    \item 记分牌：记分牌技术的目标是在资源充足时，尽可能早地执行没有数据阻塞的指令，达到每个时钟周期执行一条指令。如果某条指令被暂停，而后面的指令与流水线中正在执行的或被暂停的指令不相关，那么后面的指令可以继续流出并执行。记分牌电路负责记录资源的使用，相关检测，以及控制指令的流出与执行。
    \item Tomasulo：只要操作数有效，就将其取到保留站，避免指令流出时才到寄存器中取数据，这就使得即将执行的指令从相应的保留站中取得操作数，而不是从寄存器中。指令的执行结果也是直接送到等待数据的其它保留站中。
  \end{enumerate}
  两者的区别在于Tomasulo算法将冲突检测和指令执行区分开，指令计算的结果通过相关通路直接从功能部件送入对应的保留站中而不一定是写寄存器。与之相比，记分牌集中控制冲突的检测和指令的执行，将结果首先写入及寄存器。
  
  \item 开发指令级并行的技术和方法：
  
  开发指令级并行的技术和方法包括指令静态和动态调度、解决控制相关技术和多指令流出技术。指令的静态调度是由编译器完成的，包括循环级并行的处理、寄存器换名和指令调度等。动态调度包括记分牌技术和Tomasulo算法。解决控制相关的技术包括分支预测缓冲技术、分支目标缓冲技术和前瞻执行技术。多流出技术实现了在每个周期流出多条指令，主要包括超标量技术和超长指令字技术。
    
\end{enumerate}

\newpage
\chapter{存储系统}
\section{名词解释/填空}
\begin{enumerate}
  \item 在存储层次中,“Cache-主存”层次为了弥补主存\blank{速度}不足,“主存-辅存”层次为了弥补主存\blank{容量}的不足.(2008、2011、2012、2015、2016)
  \item \textbf{虚拟cache}:虚拟Cache是指可以直接用虚拟地址进行访问的Cache,其标识存储器中存放的是虚拟地址,进行地址检测用的也是虚拟地址.(2001、2009)
  \item \textbf{存储体冲突}:\blank{多体交叉存储器}中,两次独立的存储器访问请求在\blank{同一个存储周期}中访问\blank{同一个}存储体,就造成存储体冲突.(2001、2009、2011、2014、2016)
  \item Cache的三种类型不命中
  \begin{enumerate}
    \item \textbf{强制性不命中(Compulsory Miss)}:当第一次访问一个块时,该块不在Cache中,需要从下一级存储器中调入Cache,这就是强制性不命中.(2002、2004、2010)
    \item \textbf{容量不命中(Capacity Miss)}:程序执行时所需的块不能全部调入Cache,则当某些块被替换后,若又重新被访问,就会发生容量不命中.(2003)
    \item \emph{冲突不命中(Conflict Miss)}:在组相联或者直接映像Cache中,若多个的块映像到同一组(块)中,则会出现某个块被别的块替换,然后又被重新访问的情况,就会发生冲突不命中.
  \end{enumerate}
  \item 映像规则(2005)
  \begin{enumerate}
    \item \textbf{全相联映像(Fully Associative)}:把主存中任意一块放置到Cache中任意一个位置
    \item \textbf{直接映像(Direct Mapping)}:主存中每一块放置到Cache中唯一位置
    \item \textbf{组相联映像(Set Associative)}:主存中每一块放置到Cache中唯一一个组中任意位置
  \end{enumerate}
  \item 预取方式
  \begin{enumerate}
    \item \emph{寄存器预取}:把数据取到寄存器中
    \item \emph{Cache预取}:把数据取到Cache中
    \item \emph{故障性预取}:预取时,若出现\blank{虚地址故障}或\blank{违反保护权限},就会发生异常
    \item \textbf{非故障性预取(非绑定预取,nonbinding)}:当出现虚地址故障或违反保护权限时,不发生异常,而是放弃预取,转为空操作.非绑定预取能够返回\blank{最新数据值},并且保证对数据实际的存储器访问返回的是最新的数据项(2008、2009)
  \end{enumerate}
  \item TLB是一个专用的(\emph{\underline{高速缓存部件}}),用于存放近期经常使用的(\emph{\underline{页表项}}),其内容是页表部分内容的一个(\emph{\underline{副本}}).(2007、2012)
\end{enumerate}
\section{简答}
\begin{enumerate}
  
  \item \emph{减少Cache失效开销的策略}(2002):

  采用两级Cache；读不命中优先于写；写缓冲合并；请求字处理技术；非阻塞Cache
  \item 减少Cache命中时间的策略:
  
  容量小且结构简单的Cache；虚拟Cache；访问流水化；多体Cache；路预测；Trace Cache；
  \item 降低Cache不命中率的策略：
  
  调节Cache块大小，增加Cache容量；提高相联度；采用Victim Cache；采用伪相联Cache；硬件预取；编译器控制的预取；编译优化；
  \item {\color{grey}\emph{简述两级Cache的工作原理:}(2001)
  
  答：在原有Cache和存储器之间增加另一级Cache，构成两级Cache，这样就可以把第一级Cache做的足够小，使其能够和快速CPU的时钟周期相匹配；同时把第二级Cache做的足够大，使其能捕获更多本来需要到主存去的访问，降低实际不命中开销，克服CPU和主存之间的性能差距，使存储器和CPU性能匹配。}

  \item {\color{grey}\emph{简述TLB的工作原理}(2001):
  
  TLB用于存放近期经常使用的页表项，其内容是页表部分内容的一个副本。进行地址转换时，直接查找TLB，只有在TLB不命中时，才需要访问内存中的页表，也称为快表或地址变换缓冲器，是一种能够实现快速地址变换的技术。}
  
  \item {\color{grey}\emph{cache-主存 与 主存-辅存层次的区别}:(2004)}
  \begin{table}[H]
    \centering
    \textcolor{grey}{
    \begin{tabular}{c|c|c}
      \hline
      &Cache-主存层次&主存-辅存层次 \\
      \hline  
      目的&为了弥补主存速度不足&为了弥补主存容量不足\\
      \hline
      存储管理的实现&全部由硬件实现&主要由软件实现\\
      \hline
      访问速度的比值(第一级比第二级)&几比一&几万比一\\
      \hline
      典型块大小&几十个到几百个字节&几千个以上字节\\
      \hline
      CPU对第二级的访问&可直接访问&均通过第一级\\
      \hline
      不命中时CPU是否切换&不切换&切换到其它进程\\
      \hline
    \end{tabular}}
  \end{table}
\end{enumerate}

\newpage
\chapter{互连网络}
\section{名词解释/填空}
\begin{enumerate}
  \item \emph{互连网络}：将对称系统或分布式系统中的节点连接起来所构成的网络，这些节点可能是处理器、存储器模块或其它设备，它们通过互连网络进行信息交换。
  \item \emph{片上网络}:将“报文交换”的思想引入到片上互连结构中，构成了“片上网络”,它具有更高的可扩展性和可重用性。
  \item 在拓扑上,互连网络为输入和输出两组节点之间提供了一组\emph{\underline{互连}}或\emph{\underline{映像}}.
  \item \textbf{均匀混洗(shuffle)}: 输入左移一位；\textbf{超立方体路由}:特定位置反；设互连网络的输入为$(x_{k-1},\cdots,x_1,x_0)$,则均匀混洗输出是y=\blank{$x_{k-2},\cdots,x_1,x_0,x_{k-1}$},超立方体输出是y=\blank{$x_{k-1},\cdots,\bar{x_j},\cdots,x_1,x_0$}。(2010)
  \item \emph{静态互连网络}:由点和点直接相连而成
  \item \emph{动态互连网络}:由\underline{\emph{开关通道}}实现,可以动态改变结构
  \item \emph{节点度}:与节点相连接的边的数目称为节点度,这里的边表示链路或通道,进入节点的通道数为入度,从节点出来的通道数为出度
  (\emph{节点度=入度+出度})(2008).
  \item \textbf{网络直径}:网络中任意两个节点间\blank{最短}路径长度的\blank{最大值}叫做(\emph{\underline{网络直径}}).(2002、2004、2006、2009、2010、2012、2014、2016、2017)
  \item \textbf{等分宽度}:将网络切成\blank{任意相等两半的各种切法中},沿切口的\blank{最小通道边数}称为等分带宽.(2009、2011、2013、2014、2015)
  \item 对于一个网络,如果从任何一个节点看,拓扑结构都一样,则称此网络为\blank{对称网络}。
  \item \emph{路由}:在网络通信中对路径的选择与指定.
  \item \textbf{虚拟自适应}:将一个\blank{物理通道}分成几个\blank{虚拟的通道}，根据后续各虚拟通道的\blank{资源或网络}情况自适应选择后续通道。(2003、2007、2012、2015)
  \item \textbf{虫孔路由(Worm hole)}:把信息包分成(\emph{\underline{小片}}),片头带(\emph{\underline{目的地址}}),所有片以不可分离的(\emph{\underline{流水方式}})通过片缓冲区进行传输路由 .(2001、2004、2007、2012
  \item \emph{通讯延迟}：发送开销+跨越时间+传输时间+接收时间。
  \item \emph{超结点}:每个结点内可能还包含较小数目的处理器，这些处理器之间互连形成簇，这样形成的结点叫做超结点。
\end{enumerate}
\section{简答题}
\begin{enumerate}
  \item \emph{简单比较动态网络中总线、多级网络、交叉开关的特点:}(2003、2008、2009)
  \begin{itemize}
    \item 总线结构：系统总线在处理机、I/O子系统、存储模块或辅助存储设备之间提供了一条公用通信通路。主动设备或主设备产生访问存储器的请求，被动设备或从设备则响应请求。在多个请求的情况下，总线通过仲裁分配使用权。公用总线是在分时基础上工作的。总线结构最简单，但争用最严重，可用带宽较窄。
    \item 多级网络：多级网络可用于构造大型多处理机系统。每一级都采用了多个开关，相邻级开关之间都有固定的级间连接。主要优点是采用模块结构，可扩展性较好，然而其时延随着网络的级数增加而上升。
    \item 交叉开关：它把N台处理机和M个存储器连接起来，网络中的每个交叉点是一个允许任何一台处理机和任何一个存储器连接的开关。属于无阻塞置换网络。交叉开关的硬件复杂性较高，但交叉开关的带宽和路由性能最好，适用于规模较小的网络。
  \end{itemize}
  
\end{enumerate}

\newpage
\chapter{多处理机}
\section{名词解释/填空}
\begin{enumerate}
  \item \textbf{Home节点(宿主节点)}:是指存放\blank{需要访问}的\blank{存储单元}及\blank{相应目录项}的节点.(2008、2009、2016)
  \item \emph{本地节点(local node)}:发出\blank{访问请求}的节点.
  \item \emph{远程节点(remote node)}:拥有\blank{被访问存储块副本}的节点.
  \item \emph{拥有者(owner)}是指唯一拥有\blank{Cache块副本}的处理器.(2008)
  \item \textbf{栅栏同步(Barrier)}:栅栏强制所有的到达该栅栏的进程进行等待,直到(\emph{\underline{全部的进程}})到达栅栏,然后(\emph{\underline{释放}})全部的进程,从而形成同步.(2003、2007、2013、2016)
  \item \emph{旋转锁(spin locks)}：处理器环绕一个锁不停地旋转而请求获得该锁。
  \item 同时多线程(Simultaneous Multi Threading, SMT)是同时实现(\emph{\underline{指令级}})和\blank{线程级}的并行,每拍有(\emph{\underline{多个指令槽}}),可以安排多个线程的(\emph{\underline{多条指令}})同时流出。(2005、2009、2011、2014、2015)
  \item 同步硬件原语:用于构造同步操作的基本原语。  
  \item MIMD计算机分类、存储器系统结构
  \begin{enumerate}
    \item \emph{集中式共享存储器结构(Centralized Shared-Memory Architecture)}:处理器较少，通过总线互连共享一个集中式的物理存储器。因为主存单一，且这个主存对各处理器的关系是对称的，从各处理器访问它的时间相同，所以称其为\textbf{对称式共享存储器多处理机(Symmetric shared-memory Multi processor, SMP)}，也称为\textbf{UMA(Uniform Memory Access)}结构。由于增加处理器会使可能的数据通路数量大大增加，从而导致可用带宽减小，因此UMA可扩展性差。(2002)
    \item \emph{分布式存储器多处理机}:存储器在物理上是分布的，可以支持较大数目的处理器，系统中每个节点包含了处理器、存储器、I/O以及互连网络的接口。分布式存储器结构需要高带宽的互连网络。如果大多数访问是针对本节点的局部存储器，则可降低对存储器和互连网络的带宽要求，对局部存储器的访问延迟低。分布式存储器结构最主要的缺点是处理器之间的通信较为复杂。具有两种存储器系统结构和处理器通信方式：
    \begin{itemize}
      \item 把物理上分离的所有存储器作为统一的\blank{共享逻辑空间}进行编址，任何处理器都可访问任何存储单元，这类系统称为\textbf{分布式共享存储器系统(Distributed Shared-Memory, DSM)}，此处共享是\blank{地址空间上}的共享，不具有集中的存储器，也被称为\textbf{NUMA}，，这是因为其\blank{访存时间}取决于\blank{数据}在存储器中的\blank{存放位置}。(2011、2013、2014、2015、2017)
      \item 把每个节点中存储器编址为一个\blank{独立的地址空间}，不同节点地址空间独立，每个节点中存储器只能由本地处理器进行访问，远程处理器不能对其进行直接访问，这种计算机系统多以\blank{机群}形式存在。
    \end{itemize}
  \end{enumerate}
\end{enumerate}

\section{简单题}
\begin{enumerate}
  
  \item \emph{什么是多处理机的相关性和一致性}:(2007、2008、2010、2011、2012、2014、2015、2016、2017)
  
  如果每次读取某一数据项都会返回该数据项的最新写入值，则这个存储器系统就是相关的(coherent)。相关性(coherence)是指读操作可能返回什么值。一致性(consistence)是指什么时候读操作才能得到新写入的值。
      
  \item \emph{监听协议的工作原理:}(2003、2005、2010、2014)
  
  Cache中除了包含数据块的副本以外，也保存着各个块的共享状态信息。实现监听协议的关键有三个方面：
  \begin{itemize}
    \item 处理器之间通过一个可以实现广播的互连机制相连，通常采用的是总线；
    \item 当Cache响应本地处理器的访问时，如果它涉及全局操作，其Cache控制器就要在获得总线的控制权后，在总线上发出相应的消息。
    \item 所有的处理器都一直在监听总线，检测总线上的地址在其Cache中是否有副本，若有，则响应消息，并进行相应的操作。
  \end{itemize}
  获取总线控制权的顺序性保证了写操作的串行化。
  
  Cache发送到总线上的消息事务主要有以下三种：读不命中、写不命中、作废。其中，“写不命中”和“读不命中”表示本地CPU对Cache进行读访问和写访问不命中，这时都需要通过总线找到相应数据块的最新副本，然后调入本地Cache。对于写直达Cache，数据最新值由存储器提供，对于写回Cache，若数据最新值在某个处理器的Cahce中，则由该Cache向请求方提供数据块，并停止由读不命中和写不命中引发的对存储器的访问；“作废”用来通知其它处理器作废相应的副本。
  
  在一个基于总线的集中共享多处理机系统中，监听协议下Cache块有以下三种状态：
  \begin{itemize}
    \item 共享:在一个或多个处理器上具有该块的副本，且主存中的值为最新值；
    \item 无效:所有处理器中的Cache都没有该块的副本；
    \item 已修改:仅有一个处理器上有此块的副本，且已对此块进行了写操作，而主存中的数据块仍为旧的。
  \end{itemize}
  
  Cache本来就有的标识用来实现对总线的监听，将总线上的地址和Cache内的标识进行比较，就能找到相应的Cache块；通过每个块的有效位可以实现作废机制，当要作废一个块时，只需将其有效位置为无效即可；为了分辨某个数块是否共享，通过给每个Cache块增设一个共享位来表示该块是处于共享状态还是已修改状态。
    
  \begin{figure}[H]
    \centering
    \caption{写回Cache下响应本地CPU请求和响应总线消息的Cache状态转换图}
    \includegraphics[height=0.35\textwidth]{figures/listenprotocol.png}
  \end{figure}
  
  \item 写直达Cache与写回Cache最大的区别在于，本地处理器不需要读取另一个处理器的脏Cache块。在写直达Cache中，共享或已修改的Cache块都与主存保持一致性，当发生读失效或写失效时，不再将被替换的块强制写回内存。CPU每次写Cache时都会更新主存，所以在处理器产生读失效后就会直接访问主存。
  
  \begin{figure}[H]
    \centering
    \caption{写直达Cache下响应本地CPU请求和响应总线消息的Cache状态转换图}
    \includegraphics[height=0.35\textwidth]{figures/listenprotocol(writethrough).png}
  \end{figure}
  
  \item \emph{加入干净专有(只读)状态后的监听协议工作原理}:(2006、2012、2017)
  
  增加干净专有状态后，当CPU读取缺失时，首先判断其它处理器上是否有该块的副本，若有，则将本地Cache块状态标记为“共享”，否则标记为“干净专有”；对“干净专有”块写后，其状态转换为“专有”，处于“干净专有”的Cache块响应总线上的写入缺失转换为“无效”状态，响应读取缺失转换为“共享”状态。
  
  \begin{figure}[H]
    \centering
    \caption{增加干净专有状态后，响应本地CPU请求和响应总线消息的Cache状态转换图}
    \includegraphics[height=0.4\textwidth]{figures/listenprotocol(clean).png}
  \end{figure}
  
  
  \item \emph{目录协议的工作原理}:(2007、2011、2015)
  
  物理存储器中数据块的共享状态被保存在一个称为目录的地方。存储器的每一个数据块在目录存储器中对应有一项，目录项用于记录该块的状态以及哪些Cache中有副本等消息。对于任何一个数据块都可以根据其地址块速找到相关的信息，这使得目录协议避免了广播操作。目录协议常采用位向量记录哪些Cache中有副本，位向量中的每一位对应于一个处理器。位向量指定的处理机的集合称为共享集。

  目录协议中，存储块的状态有三种：未缓存、共享和独占:
  \begin{enumerate}
    \item 未缓存状态表示数据块尚未被调入Cache。
    \item 共享状态表示该块在一个或多个处理机上有该块的副本，且这些副本与存储器中的块相同。
    \item 独占状态表示仅有一个处理机有该块的副本，且该处理机已对其进行了写操作，所以其内容是最新的，而存储器中该块的数据已经过时。
  \end{enumerate}
  为了提高实现效率，在每个Cache中还跟踪记录了每个Cache块的状态。在目录协议中有三种节点，分别是：
  \begin{enumerate}
    \item 本地节点，表示发出访问请求的节点。
    \item 宿主节点，表示包含要访问的存储单元及其目录项的节点。
    \item 远程节点，表示拥有相应存储块副本的节点。
  \end{enumerate}
  
  目录协议采用点到点的通信。本地节点把请求发送给宿主节点的目录，再由目录控制器有选择地向远程节点发出相应的消息，使远程节点进行相应的操作，并进行目录中状态信息的更新。
    
  \begin{figure}[H]
    \centering
    \caption{响应本地CPU请求的Cache状态转换图，远程节点响应宿主节点消息的Cache状态转换图，目录接收消息的状态转换图}
    \includegraphics[height=0.6\textwidth]{figures/content.png}
  \end{figure}
  
  \item \emph{一台超结点的分布共享多处理机，结点内部运行监听协议，结点之间运行目录协议，试述其工作原理}:(2008、2009、2013、2016)
  
  \item \emph{松弛一致性模型、特点及其硬件支持}(2003、2006、2007、2009、2010、2012、2014、2015、2017):
  松弛一致性模型的关键特点是允许乱序执行读取和写入操作，但是用同步操作来实施排序。同步程序的表现就像处理器具备顺序连贯性一样。松弛一致性在保证程序正确性前提下增加了指令执行的并行，所以采用松弛一致性模型的机器可以提高性能。
  
  顺序连贯性模型保持了$W\rightarrow R,W\rightarrow W,R\rightarrow R,R\rightarrow W$四种读写顺序，根据松弛的读取顺序的内容，可以将松弛一致性模型划分为四类：
  \begin{itemize}
    \item 完全存储排序模型，松弛了$W\rightarrow R$顺序。这种模型维护写的次序，采用写缓存，能够允许处理机在其写的操作被所有别的处理机看到之前就继续进行读。在硬件支持上为写缓冲的读旁路等。
    \item 部分存储排序模型，松弛了$W\rightarrow W$顺序。这种模型允许非冲突写隐含地乱序进行，对同步操作扔需将写操作挂起，因为它引起写保护。在硬件支持上为写的流水化或其它写并行等。
    \item 弱排序模型，松弛了$R\rightarrow W$，$R\rightarrow R$顺序，在硬件支持为不封锁读。
    \item 释放一致性模型，松弛了$W\rightarrow S_A$，$R\rightarrow S_A$，$S_R\rightarrow W$，$S_R\rightarrow R$顺序，这种模型区分同步操作中的访问一个共享变量的获取操作$S_A$和释放操作$S_R$。在硬件支持上为不封锁读、旁路、无序写等。
  \end{itemize}
  
  \item \emph{大规模机器的同步有哪些软件和硬件方法}:(2010、2011、2012、2013、2014、2016、2017)
  \begin{enumerate}
    \item 软件方法
    \begin{itemize}
      \item 延迟等待旋转锁：加锁失败时，推延进程的等待时间。一般是在失败时，延迟时间指数增大。
      \item 软件排队锁：可以排队记录等待的进程，当锁释放时发送出一个已经确定的等待进程。软件实现用数组将要进行同步的进程排队，按排序进行同步操作。
      \item 组合树栅栏：是多个请求在局部结合起来形成树的一种分级结构，局部组合的分支数量远小于总的分支数量，因此组合树栅栏降低冲突的原因是将大冲突化解称为多个并行的小冲突。
    \end{itemize}
    \item 硬件方法
    \begin{itemize}
      \item 硬件排队锁：可以排队记录等待的进程，当锁释放时发送出一个已经确定的等待进程。硬件实现一般是在基于目录的机器上，通过硬件向量等方式来进行排队和同步控制。
      \item 硬件原语：用硬件实现，能够以原子方式读出和修改存储单元。引进一种原语减少栅栏计数时所需的时间，从而减小串行形成的瓶颈。
    \end{itemize}
  \end{enumerate}
  
  \item \emph{时延隐藏技术}:(2001、2004、2007、2013)
  时延隐藏：将通信和计算或多次通信重叠。MPP系统采用了包括数据预取、相关性Cache、松弛一致性、多现场这几种时延隐藏技术。
  \begin{itemize}
    \item 数据预取：在数据使用之前就将其取到近处；
    \item 相关性Cache：减少对共享数据访问的竞争及时延；
    \item 松弛一致性：在保证程序正确性前提下增加指令执行的并行；
    \item 多现场：在产生时延时进行现场切换转而执行其它程序。
  \end{itemize}
  
  \item \emph{栅栏同步怎样完成同步过程?(2011、2015)；什么是栅栏同步?(2012、2017);在标准的栅栏同步中，设单个处理器的通过时间(包括更新计数和释放锁)为C，给出N个处理器一起进行一次同步所需要的时间表达式。(2004、2012、2014、2017)；在采用k元组合树的栅栏同步中，设单个处理器的通过时间(包括更新计数和释放锁)为C，求N个处理器器一起进行一次同步所需的时间。(2005)；采用排队锁和Fetch-and-Increment实现栅栏同步和旋转锁实现栅栏同步的性能比较}:
  \begin{enumerate}
    \item 栅栏同步过程:
    
    栅栏同步强制所有到达该栅栏的进程进行等待，直到全部的进程到达栅栏，然后释放全部的进程，从而形成同步。栅栏的典型实现是用两个旋转锁，一个用来保护计数器，该计数器记录已到达该栅栏的进程数，另一个用来封锁进程直至最后一个进程到达栅栏。栅栏的实现要不停地检测指定变量，直到它满足规定的条件。下面是一个典型的实现：
    \begin {lstlisting}[language=C] 
      lock(counterlock);
      if(counter==0)release=0;
      count=count+1;
      unlock(counterlock);
      if(count==total){
        count=0;
        release=1;
      }
      else{
        spin(release);
      }
    \end{lstlisting}
    
    \item 标准栅栏同步时间
    
    忽略读写锁的时间。N个处理器中的每一个都需要C个周期来锁住与栅栏相关的计数器并修改它的值，然后释放锁。考虑最坏情况，所有N个处理器都要对计数器加锁并修改它的值。由于锁只能顺序访问计数器，在同一时间只能有一个处理器修改计数器的数据，所以总共要花费NC个时钟周期使得所有的处理器都到达栅栏。
    
    \item k元组合树栅栏同步时间
    
    树中每个节点组合k个处理器，提供一个单独的计数器和锁，因而在每个节点有k个进程进行竞争。每个节点需要kC的时间通过。
    
    树中一共有$L=\log_kN$层，共有节点$\sum_{i=1}^{L}\frac{N}{k^i}$个。因此，最坏情况下所有的节点要串行处理，n个处理器共需要$kC\sum_{i=1}^{L}\frac{N}{k^i}$的时间完成同步。最快的情况是同一层中的节点并行处理，需要$Lkc$的时间。
      
    \item 不同栅栏同步实现的性能比较
    \begin{itemize}
      \item 排队锁实现栅栏同步：对n个处理器，每个处理器都初始加锁产生1个总线事务，其中一个成功获得锁并在使用后释放锁，第一个处理器将有n+1个总线事务。每一个后续处理器需要2个总线事务：一个获得锁，另一个释放锁。因此总线事务为:$(n+1)+2(n-1)=3n-1$。
      \item Fetch-and-Increment实现栅栏同步：对于n个处理器，需要n此Fetch-and-Increment操作，访问count变量的n次Cache失效和释放时n次Cache失效，总共需要3n个总线事务。
      \item 标准栅栏：i个处理器竞争锁的时候，包括访问该锁的i个LL操作，试图锁住该锁的i个SC操作，以及1个释放锁的存操作。因此一共需要总线事务$\sum_{i=1}^n(2i+1)=n^2+2n$个总线事务。
    \end{itemize}
    
  \end{enumerate}
  
  \item \emph{比较同时多线程(Simultaneous Multithreading)、粗粒度多线程和细粒度多线程及其特点}:(2006、2010、2013)
  \begin{itemize}
    \item 细粒度多线程能够在每条指令之间进行线程切换，从而使多个线程交替执行，通常以时间片循环的方式实施线程交替，在循环过程中跳过停顿的进程。
    \begin{itemize}
      \item 优点：能够隐藏由于长时间或短时间停顿引起的吞吐率的损失。
      \item 缺点：降低了每个线程的执行速度，这是因为即使没有任何停顿的线程也不能连续执行，而且会因为其它线程指令的插入执行而被延迟。
    \end{itemize}
    \item 粗粒度多线程的切换只发生时间较长的停顿出现的时候，通过线程间的切换部分隐藏了代价较高、时延较长的停顿带来的吞吐率的损失。
    \begin{itemize}
      \item 优点：降低了线程的切换次数，不会减慢每个独立线程的执行。
      \item 缺点：减少吞吐率损失的能力有限，特别是对于较短的停顿来说更是如此。
    \end{itemize}
    \item 同时多线程在多流出、动态调度的处理器上同时开发线程级并行性和指令级并行性，每拍有多个指令槽，可以安排多个线程的多条指令同时流出。
    \begin{itemize}
      \item 优点：提高吞吐率，且不损失单个线程的性能。
      \item 缺点：实际中的一些因素，如活跃线程的个数、缓冲大小限制、可并行指令及从多个线程中取指的能力，仍将限制流出槽的利用率。
    \end{itemize}
  \end{itemize}
  
  \item \emph{同时多线程的并行工作原理及其在体系结构实现上的基础}:(2007)
  \begin{itemize}
    \item \emph{工作原理}:
    
    同时多线程是一种在多流出、动态调度的处理器上同时开发线程级并行性和指令级并行性的技术。通过动态调度和寄存器重命名机制，每拍有多个指令槽，可以安排多个线程的多条指令同时流出而不考虑指令间的相关性，相关性由动态调度负责处理。
    \item \emph{结构基础}:
    
    使用动态调度技术的处理器已经具备了开发线程级并行所需的硬件设置。具体来说，动态调度超标量处理器有大量的虚拟寄存器，可以用来保存每个独立线程的寄存器状态。由于寄存器重命名机制提供了唯一的寄存器标识符，多个线程的指令可以在数据路径上混合执行，而不会导致线程间源操作数和目的操作数的混乱。
  
    \item \emph{具体实现}:
    只要在支持单线程的处理器上实现以下几点，就可以实现同时多线程
    \begin{itemize}
      \item 设置多个独立的重命名表，以保存每个独立线程的寄存器状态。
      \item 让取值部件和指令Cache并发预取多个线程指令流，并分别设置各自的PC；
      \item 指令完成时，处理器为不同的线程提供指令确认。
    \end{itemize}
  \end{itemize}

  \item 标准栅栏存在的问题，及其改进措施：
  
  假设所有进程在离开栅栏时，其中有一个进程还没有离开栅栏，即停留在旋转等待操作上，这时如果有新的进程又到达了栅栏，而上一次循环的进程最后那个还没来得及离开栅栏，那么这个块进程会将release重新置为0，从而将慢进程捆在栅栏上，这样所有的进程都会处于无限等待状态，因为进程的总数达不到total。
  
  改进的办法是当进程离开栅栏是进行计数，在上次栅栏使用的所有进程离开前，不允许任何进程重用并初始化栅栏，这样会明显增加栅栏的延迟和竞争。
  另一种方法是sense$\li$reversing栅栏，每个进程均使用一个私有变量local$\li$sense，该变量初始化为1。下面是一个sense$\li$reversing的实现：
  \begin {lstlisting}[language=c]
    local_sense=!local_sense;
    lock(counterlock);
    counter++;
    unlock(counterlock);
    if(count==total){
      count=0;
      release=local_sense;
    }
    else{
      spin(release==local_sense);
    }
  \end{lstlisting}
  

  \item {\color{grey}LL/SC同步原语的原理：
  
  LL指令称为\emph{链接载入}或\emph{锁定载入}指令，SC指令称为\emph{条件存储}指令。对于链接载入指令所指定的存储器位置，如果其内容在对同一位置执行条件存储之前发生了改变，那么条件存储指令就会执行失败。如果两条指令之间进行了上下文切换(不能有的处理器的指令在链接载入和条件存储指令之间执行)，那么条件存储也会执行失败。}

  \item {\color{grey}多处理Cache的一致性及其解决方案:
  
  如果允许共享数据进入Cache，就可能出现多个处理器的Cache中都有同一存储块的副本的情况，当其中某个处理器对其Cache中的数据就行修改后，就会使其Cache中的数据与其它Cache中的数据不一致。这就是多处理机的Cache一致性(Cache coherence)。
  
  保持一致性要求的两种协议模式：
  \begin{itemize}
    \item 写作废协议(Write Invalidate)：在处理器写某个数据项之前保证它对该数据项有唯一的访问权，具体做法是在进行写入之前，把所有其它Cache中的副本全部作废；
    \item 写更新协议(Write Update):在一个处理器写某个数据项时，通过广播使其它Cache中所有对应的数据项副本进行更新。
  \end{itemize}
  写更新协议和写作废协议的性能差别来自三个方面:
  \begin{itemize}
    \item 对同一数据的多个写而中间无读操作的情况，写更新协议需要进行多次写广播操作，而写作废协议只需一次作废操作；
    \item 对同一块中多个字进行写，写更新协议对每个字的写均要进行一次广播，而在写作废协议下仅对本块的第一次写时进行作废操作即可。写作废是针对Cahce块进行操作的，写更新是针对字(或字节)进行操作的；
    \item 从一个处理器写到另一个处理器读之间的延迟通常在写更新模式中较低，因为它在写数据时马上更新了其它Cache中相应的内容(假设读的处理器Cahce中有此数据)，而在写作废协议中，需要读一个新的备份。
  \end{itemize}}
  
  \item {\color{grey}存储器一致的三个条件:
  \begin{itemize}
    \item 处理器P对X单元进行一次写之后又对X进行读，读和写之间没有其它处理器对X单元进行写，则读的返回值总是写进的值；
    \item 一个处理器对X单元进行写之后，另一个处理器对X单元进行读，读和写之间无其它写，则读X单元的返回值应为写进的值；
    \item 对同一单元的写是顺序化的，即任意两个处理器对同一单元的两次写，从处理器看来顺序是相同的。
  \end{itemize}}
  
\end{enumerate}

\begin{comment}

\newpage
\section{计算题}
\subsection{流水线}
\begin{enumerate}
  \item 2001.三.2:多功能动态流水线、时空图、吞吐率、效率、加速比
  
  令
  \begin{align*}
    x_1+y_1&=d_1,x_2+y_2=d_2,x_3+y_3=d_3\\
    x_4+y_4&=d_4,x_5+y_5=d_5,x_6+y_6=d_6\\
    d_1\times d_1&=c_1,d_3\times d_4=c_2,d_5\times d_6=c_3\\
    c_1\times c_2&=e_1,e_1\times c_3=e_2
  \end{align*}
  采用最快的处理方式，流水线的时空图为：
  \begin{figure}[H]
    \centering
    \includegraphics[height=0.2\textwidth]{figures/2001.2.png}
  \end{figure}
  
  $\text{吞吐率}=\frac{\text{任务数}}{\text{时钟周期数}}=\frac{11}{19}$\newline
  $\text{效率}=\frac{44}{95}$\newline
  $\text{加速比}=\frac{\text{不采用流水线所用的时间}}{\text{采用流水线所用的时间}}=\frac{4\times 11}{19}=\frac{44}{19}$
\end{enumerate}
\subsection{存储系统}
\begin{enumerate}
  \item 2001.三.4
  
  当块的大小分别为32,64,128时，1KB、16KB和64KB的Cache失效率最低。
  失效率最低时，平均访存时间为：
  \begin{align*}
    5ns+100ns\times 13.34\%=18.34ns\\
    5ns+100ns\times 7.00\% = 12ns \\
    5ns+100ns\times 1.02\%=6.02ns
  \end{align*}
  
  \item 2002.三.1
  
  $\text{局部失效率}=\frac{\text{该级Cache的不命中次数}}{\text{到达该级Cache的访存次数}}$\newline
  $\text{全局失效率}=\frac{该级Cache的不命中次数}{CPU总访存次数}$\newline
  对于第一级Cache，$\text{局部失效率}=\text{全局失效率}=\frac{40}{1000}=4\%$\newline
  对于第二级Cache，$\text{局部失效率}=\frac{20}{40}=50\%$,$\text{全局失效率}=\frac{20}{1000}=2\%$
  
\end{enumerate}

\subsection{向量处理机}
\begin{enumerate}
  \item 2002.三.2
  \begin{enumerate}
    \item 每次循环需要执行9条指令，因此需要的时间为$9\times 5\times n+2\times 5=45n+10$个时钟周期。
    \item 调度后的指令为
    \begin{table}[H]
      \centering
      \begin{tabular}{lll}
        &LW & R1,a \\
        &ADDI & R8,R30,\#8n \\
        Loop:&LW & R2,0(R30) \\
        & MULT & R2,R1,R2 \\
        & ADDI & R30,R30,\#8 \\
        & SUB & R20,R8,R30 \\
        & LW & R4,0(R31) \\
        & ADD & R4,R2,R4 \\
        & SW & R4,0(R31) \\
        & BNZ & R20,Loop \\
        & ADDI & R31,R31,\#8 \\
      \end{tabular}
    \end{table}
    总的时钟周期数为$5+(9n+2-1)=9n+6$，吞吐量为$\frac{9n+2}{9n+6}$,时空图略
    \item     
  \end{enumerate}
\end{enumerate}

\subsection{指令级并行}
\begin{enumerate}
  \item 2003.三.3
  \begin{enumerate}
    \item 不进行代码顺序调整的情况下，代码执行的时钟周期如下
    \begin{table}[H]
      \centering
      \begin{tabular}{lllll}
        loop: & ld & f5,0(r1)&1 \\
        & ld & f6,0(r2)&2 &load指令延迟2个时钟周期\\
        & stall&&3 \\
        & stall&&4\\
        & multd & f7,f5,f6 &5&浮点乘法执行4个时钟周期\\
        & stall&&6 \\
        & stall&&7\\
        & stall&&8\\
        & addd & f4,f4,f7&9\\
        & addi & r1,r1,\#8&10\\
        & addi & r2,r2,\#8&11\\
        & subi & r3,r3,\#1&12&与分支指令相关，延迟一个周期\\
        & stall&&13 \\
        & bnez & r3, loop&14
      \end{tabular}
    \end{table}
    因此不进行代码顺序调整情况下，执行一次迭代的时间为14个时钟周期
    \item 调整后的代码执行顺序如下：
    \begin{table}[H]
      \centering
      \begin{tabular}{lllll}
        loop: & ld & f5,0(r1)&1 \\
        & ld & f6,0(r2)&2 &load指令延迟2个时钟周期\\
        & addi & r1,r1,\#8&3\\
        & addi & r2,r2,\#8&4\\
        & multd & f7,f5,f6 &5&浮点乘法执行4个时钟周期\\
        & stall&&6 \\
        & stall&&7\\
        & subi & r3,r3,\#1&8&与分支指令相关，延迟一个周期\\
        & addd & f4,f4,f7&9\\
        & bnez & r3, loop&10
      \end{tabular}
    \end{table}
  \end{enumerate}
\end{enumerate}


\subsection{多处理机}

\section{其它}
\begin{enumerate}
  \item 超线性加速比:(2002.四.2)
  一些科学应用程序通常会在小幅增加处理器数目时(2或4,增加到8或16)，实现超线性加速比。这些结果的出现通常是因为一些关键性的数据结构无法放入拥有2个或4个处理器的多处理中的聚合缓存，但却可以放入拥有8个或16个处理器的多处理的聚合缓存中。
  \item 2003.三.1 
  \begin{enumerate}
    \item 机器A的平均每条指令的执行时间为$1.8\times 20ns=36ns$，机器B的平均每条指令的执行时间为$1.2\times 25ns=30ns$
    \item $\frac{\frac{1}{36\times 20}}{\frac{1}{30\times 25}}=\frac{25}{24}$,因此机器A的性价比更高。
  \end{enumerate}
\end{enumerate}

\end{comment}

\end{document}
