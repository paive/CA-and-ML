\documentclass[a4paper]{ctexart}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{ulem}
\usepackage{multirow}
\usepackage{listings}
\usepackage{graphicx}
\newcommand{\li}{\uline{\hspace{0.5em}}}
\newcommand{\blank}[1]{(\emph{\underline{#1}})}

\begin{document}

\title{高级体系结构知识点}
\author{作者:杨森}
\maketitle

\newpage
\section{基础}
\subsection{名词解释/填空}
\begin{enumerate}
  \item (\emph{\underline{微处理器技术}})的发展带来了计算机设计的复兴,既强调(\emph{\underline{体系结构}})方面的创新,也重视技术改进的高效应用.(2006)
  \item Throughout this range in price and capabiity, the desktop market tends to be driven to optimize (\emph{\underline{price-performance}}).(2006)
  \item Power Consumption in Computer Systems Power consumption in modern systems is dependent on a variety of factors, including the chip \blank{clock frequency}, \blank{efficiency}, the disk drive speed, disk drive utilization, and \blank{DRAM}.(2013)
  \item 服务器的三个关键特征:(\emph{\underline{可用性}}),(\emph{\underline{可扩展性}}),(\emph{\underline{吞吐能力}}).(2006)
  \item 一个事件从启动到完成的事件,称为(\emph{\underline{响应时间}}),也称为(\emph{\underline{执行时间}})；仓库级计算机的操作人员可能关心的是(\emph{\underline{吞吐量}}),也就是给定时间内完成的总工作量.(2006)
  \item \textbf{计算机体系结构}:计算机系统结构是指\blank{传统机器程序员}看到的\underline{\emph{计算机属性}},即\underline{\emph{概念性结构}}和\underline{\emph{功能特性}}.(2001、2005、2008、2013)
  \item 存储程序计算机(冯诺依曼结构)的特点是:机器以(\emph{\underline{运算器}})为中心；采用存储程序原理；存储器是按照(\emph{\underline{地址}})访问的、线性编址的空间；控制流由(\emph{\underline{指令流}})流产生；指令有操作码和地址码组成；数据以(\emph{\underline{二}})进制编码表示,采用二进制运算；由\blank{运算器},\blank{存储器},\blank{输入/输出设备},\blank{控制器}组成(2007、2009、2012、2015)
  \item 程序的局部性原理是指:程序总是趋向于使用最近使用过的(\emph{\underline{数据}})和(\emph{\underline{指令}}),程序执行时所访问的存储器地址不是随机分布的,而是相对簇集,包括(\emph{\underline{时间局部性}})和(\emph{\underline{空间局部性}}):(2008、2012、2015)
  \begin{enumerate}
    \item \textbf{时间局部性}:程序即将用到的信息很可能是目前正在用的信息.(2002)
    \item \emph{空间局部性}:程序即将用到的信息很可能与目前正在使用的信息在空间上邻近.
  \end{enumerate}
  \item \textbf{软件兼容(Software Compatable)}:软件兼容是指一台计算机上的程序不加修改就可以搬到另一台计算机上正常运行.(2002)
  \item 所谓\emph{系列机}就是指具有相同的(\emph{\underline{体系结构}}),但具有不同(\emph{\underline{组成}})和(\emph{\underline{实现}})的一些列不同型号的机器.我们把不同厂家生产的具有相同体系结构的计算机称为(\emph{\underline{兼容机}}).(2008、2010、2013)
  \item \textbf{并行性(parallelism)}:并行性是指计算机系统在同一时刻或者同一时间间隔内运行多种运算或者操作,包括同时性和并发性两种含义,同时性是指两个或两个以上的时间在同一时刻发生,并发性是指两个或两个以上的事件在同一时间间隔内发生.(2002)
  \item \textbf{Amdahl定律}:当对一个系统中的某个部件进行改进后,所能获得的整个系统性能\blank{加速比},受限于该部件的\blank{执行时间}占总执行时间的\blank{百分比}.(2004、2010、2011、2014、2016)
  \item 器件发生故障的概率与\blank{时间}的关系可以使用\textbf{学习曲线}来说明。(2011)
  \item 我们把DRAM这种不供电数据丢失的存储器称为\blank{易失性}存储器，把磁盘这种不供电数据也能够保存数据的存储器称为\blank{非易失性}存储器。(2015)
\end{enumerate}
\subsection{简答题}
\begin{enumerate}
  \item 简述存储程序计算机的特点:(2002)
  
  机器以\emph{运算器}为中心；采用存储程序原理；存储器是按照\emph{地址}访问的、线性编址的空间；控制流由\emph{指令流}流产生；指令有操作码和地址码组成；数据以\emph{二}进制编码表示,采用二进制运算；由\emph{运算器},\emph{存储器},\emph{输入/输出设备},\emph{控制器}组成。

  
\end{enumerate}

\newpage
\section{指令系统}
\subsection{名词解释/填空}
\begin{enumerate}
  \item 设计指令系统包括\blank{寻址方式}，\blank{操作类型}，\blank{指令集操作}，\blank{指令系统编码}等方面。(2011、2016)
  \item \textbf{RISC}含义是\blank{精简指令集计算机},\textbf{CISC}含义是\blank{复杂指令集计算机}.(2008、2015)
  \item \textbf{寄存器-寄存器型(Load/Store型)}指令结构:操作数都来自通用寄存器组.(2001、2003)
  \item 指令系统的基本要求:
  \begin{enumerate}
    \item \emph{完整性}:在有限可用的存储空间内,对于任何可解的问题,编制计算程序时,指令系统提供的功能足够使用.
    \item \textbf{规整性}:指令系统的规整性主要包括对称性和均匀性,对称性是指所有与指令系统有关的存储单元的使用、操作码的设置等都是对称的；均匀性是指对于各种不同的操作数类型、字长、操作种类和数据存储单元,指令的设置都要同等对待.(2001、2004)
    \item \textbf{正交性}:指令中各个不同含义的字段,如操作类型、数据类型、寻址方式字段等,在编码时应该互不相关、相互独立.(2002)
    \item \emph{高效率}:指令的执行速度快、使用频率高.
  \end{enumerate}
\end{enumerate}
\subsection{简答题}
\begin{enumerate}
  \item \emph{CISC结构计算机的缺点和RISC结构计算机的设计原则}:(2004)
  
  CISC是复杂指令集计算机，缺点主要有以下几点：
  \begin{itemize}
    \item 各种指令的使用频率相差悬殊，许多指令很少用到。
    \item 指令系统庞大，指令条数很多，许多指令功能又很复杂，这使得控制器硬件变得非常复杂。
    \item 许多指令由于操作繁杂，其CPI值比较大，执行速度慢。
    \item 由于指令功能复杂，规整性不好，不利于利用流水线来提高性能。
  \end{itemize}
  
  RISC是精简指令集计算机，设计原则主要包括以下几点:
  \begin{itemize}
    \item 指令条数少、指令功能简单；
    \item 采用简单而统一的指令格式，减少寻址方式；
    \item 指令的执行在单周期内完成(采用流水线技术);
    \item 采用load-store结构，即只有load和store指令采用访问存储器，其他指令的操作都是在寄存器之间进行的；
    \item 大多数指令都采用硬连逻辑实现；
    \item 强调优化编译器的作用，为高级语言程序生成优化的代码；
    \item 充分利用流水技术来提高性能。
  \end{itemize}
\end{enumerate}

\newpage
\section{流水线}
\subsection{名词解释/填空}
\begin{enumerate}
  \item 流水线分类：
  \begin{enumerate}
    \item \emph{部件级流水线}:把处理机中的部件进行分段,在把这些分段相互连接而成.
    \item \emph{处理机级流水线}:又称指令流水线(Instruction Pipeline),把指令的执行过程按照流水方式进行处理,即把一条指令的执行过程分解为若干个子过程.
    \item \emph{系统级流水线}:又称为宏流水线(Macro Pipeline),把多个处理机串行连接起来,对同一数据流进行处理,每个处理机完成整个任务中的一部分.
    \item \emph{单功能流水线(Unifunction Pipeline)}:流水线各段之间连接固定不变,只能完成单一固定功能.
    \item \textbf{多功能流水线(Multifunction Pipeline)}:流水线各段之间可以进行不同的连接,以实现不同功能.(2004)
    \item \emph{静态流水线(Static Pipeline)}:同一时间内,多功能流水线的各段只能按照同一种功能的连接方式工作.
    \item \emph{动态流水线(Dynamic Pipeline)}:同一时间内,多功能流水线的各段可以按照不同的方式连接.
    \item \emph{线性流水线(Linear Pipeline)}:流水线各段串行连接、没有回馈.
    \item \emph{非线性流水线(Nonlinear Pipeline)}:各段除了有串行的连接外,还有反馈回路.
    \item \emph{顺序流水线(In-order Pipeline)}:流水线输出端任务流出顺序与输入端任务流入顺序完全相同.
    \item \emph{乱序流水线(Out-order Pipeline)}:流水线输出端任务流出顺序与输入端任务流入顺序可以不同.
  \end{enumerate}
  \item 对于采用指令流水线的处理器,其CPI公式为: CPI流水线 = 流水线理想CPI + (\emph{\underline{结构相关停顿导致的停顿}}) + (\emph{\underline{数据相关导致的停顿}}) + (\emph{\underline{控制相关导致的停顿}}).(2005、2007、2013)
  \item 流水线的理想CPI是衡量流水线(\emph{\underline{最高}})性能的一个指标.(2006)
  \item 相关分类
  \begin{enumerate}
    \item \textbf{结构相关}:当指令在同步重叠执行过程中,硬件资源满足不了指令重叠执行的要求,发生资源冲突.(2001、2002、2003)
    \item \textbf{数据相关}:当一条指令需要用到前面的执行结果,而这些指令均在流水线中重叠执行是产生数据相关；对于顺序指令i和j，指令i和j存在数据相关是指，指令j的\blank{操作数寄存器或存储器}是指令i要写入的寄存器或者\blank{存储单元}。(2006、2010)
    \item \emph{控制相关}:当流水线遇到分支指令和其他能够改变PC值的指令就会发生控制相关.
    \item \textbf{反相关}:如果指令j的\blank{目标寄存器}是指令i要\blank{访问}的\blank{寄存器}或\blank{存储单元}.(2011、2014、2016、2017)
    \item 输出相关:如果指令j和指令i所写的名相同,则称指令i和j发生了输出相关.
  \end{enumerate}
  \item \textbf{吞吐率(ThroughPut, TP)}:单位时间内流水线所完成的任务数量或者输出结果的数量.(2002)
  \item \textbf{定向(Forwarding)}:在发生写后读相关的情况下,将计算结果从起产生的地方直接从到其他指令需要它的的地方.(2003、2017)
  \item \textbf{分支延迟槽(Brancy Delay Slot)}:存放分支指令的后继指令，无论分支指令成功与否，都会执行分支延迟槽中的指令.(2017)
  \item \textbf{异常(Exception)}:指令正常的执行顺序得到改变.(2017)
\end{enumerate}

\newpage
\section{向量处理机}
\subsection{名词解释/填空}
\begin{enumerate}
  \item \emph{通过时间}:第一个任务从进入流水线到流出结果的时间段.
  \item \emph{排空时间}:最后一个任务从进入流水线到流出结果的时间段.
  \item 流水线的\textbf{链接(pipeline chaining)}是将流水线计算机中多个(\emph{\underline{功能部件}})按照指令要求链接在一起,构成一个\blank{长流水线},减少各个功能部件流水线(\emph{\underline{加载/建立}})和\blank{排空}的时间,提高流水线执行的效率；向量流水线的链接是在有\blank{数据(写后读)}相关的\blank{两}条指令之间,将产生数据的指令部件的\blank{结果}直接送到使用数据部件的\blank{向量寄存器/输入}.(2007、2009、2010、2011、2013、2014、2016)
\end{enumerate}

\newpage
\section{指令级并行}
\subsection{名词解释/填空}
\begin{enumerate}
  \item 当指令之间不存在\blank{相关}时，它们在流水线中是可以重叠起来并行执行的，这种指令序列中存在的潜在并行性称为\blank{指令级并行}。(2015)
  \item \textbf{基本块(Basic Block)}:一段连续的代码除了入口和出口,没有其他的分之指令和转入点,这称其为基本快.(2003)
  \item This potential overlap among instructions is called (\emph{\underline{instruction-level parallelism (ILP)}}) since the instructions can be evaluated in (\emph{\underline{parallel}}).(2006)
  \item \emph{静态调度(Static Scheduling)}:在编译期间而非程序执行过程中进行代码的调度和优化.
  \item \textbf{动态调度(Dynamic Scheduling)}:在程序的执行过程中,依靠专门硬件对代码进行调度.(2004)
  \item \textbf{乱序流出(Out of order issue)}:程序中的\blank{指令}不是按照排列的顺序流出,而是当指令需要的资源条件得到满足时即\blank{流出}.(2001、2010)
  \item \emph{乱序执行(Out of order Execution)}:指令的执行顺序与程序顺序不同.
  \item \emph{乱序完成(Out of order completion)}:指令的完成顺序与程序顺序不同.
  \item \textbf{分支预测缓冲(Branch Prediction Buffer, BPB, BHT)}:仅使用一片存储区域,记录最近一次或几次的分支特征的历史,包括两个步骤,分支预测和预测为修改.(2004)
  \item \emph{分支目标缓冲(Branch Target Buffer, BTB)}:将分支成功的分支指令和它的分支目标地址都放到一个缓冲区中保存起来,缓冲去以分支指令的地址作为标识.
  \item 在前瞻执行(speculation)中,指令的流出过程是\blank{顺序}的,但结束过程的确认是\blank{顺序}的,再定序缓冲用于保存执行完毕但尚未顺序确认的指令.(2009)
  \item \textbf{再定序缓冲(ReOrder Buffer)}:暂存指令执行的结果,使其不直接写回到寄存器或者存储器,能够在分支错误的情况下恢复现场.(2001)
  \item \textbf{超标量技术(Superscalar)}:在每个时钟周期流出多条指令,但流出的指令的条数不固定.(2003、2017)
  \item \textbf{全局代码调度(Globa code scheduling)}:把分支之前的指令调度到分支之后,或者把分支之后的指令调度到分支之前,称之为(\emph{\underline{全局}})代码调度,其目的实在保持代段\blank{数据}相关和\blank{控制}相关不变的前提下,将一段内部包含\blank{控制相关}相关的代码段压缩到尽可能最短.(2005、2017)
  \item \textbf{软流水}:\blank{循环重组技术},使得\blank{循环体}由原来不同循环中指令组成.是一种用于程序中\blank{循环结构}的指令\blank{重组}技术,又称为\blank{符号化循环展开}.(2002、2005、2007、2010)
\end{enumerate}
\subsection{简答题}
\begin{enumerate}
  \item \emph{多指令流出主要受哪些方面的限制}:(2003)
  
  处理器中指令的流出能力是有限的，主要受以下三个方面的影响：
  \begin{itemize}
    \item 程序所固有的指令集并行性。这一限制是最简单也是最根本的元素，对于流水线处理器，需要有大量可并行执行的操作才能避免流水线出现停顿。
    \item 硬件实现上的困难。多流出的处理其需要大量的硬件资源，因为每个周不仅要流出多条指令，还要执行它们。随着每个时钟周期流出指令数的增加，所需的硬件成正比例的增长。同时所需的存储器带宽和寄存器带宽也大大增加了。
    \item 超标量和超长指令字处理器固有的技术限制。超标量处理器无论采用记分牌技术还是Tomasulo技术都需要大量的硬件，VLIW处理器仅需要很少甚至不需要额外的硬件，因为这些工作全部由编译器完成。设计多流出处理器要在各个因素和技术之间进行权衡取舍。
  \end{itemize}
\end{enumerate}

\newpage
\section{存储系统}
\subsection{名词解释/填空}
\begin{enumerate}
  \item 在存储层次中,“Cache-主存”层次为了弥补主存\blank{速度}不足,“主存-辅存”层次为了弥补主存\blank{容量}的不足.(2008、2011、2012、2015、2016)
  \item \textbf{虚拟cache}:虚拟Cache是指可以直接用虚拟地址进行访问的Cache,其标识存储器中存放的是虚拟地址,进行地址检测用的也是虚拟地址.(2001、2009)
  \item \textbf{存储体冲突}:\blank{多体交叉存储器}中,两次独立的存储器访问请求在\blank{一个存储周期}中访问\blank{同一个}存储体,就造成存储体冲突.(2001、2009、2011、2014、2016)
  \item Cache的三种类型不命中
  \begin{enumerate}
    \item \textbf{强制性不命中(Compulsory Miss)}:当第一次访问一个块时,该块不在Cache中,需要从下一级存储器中调入Cache,这就是强制性不命中.(2002、2004、2010)
    \item \textbf{容量不命中(Capacity Miss)}:程序执行时所需的块不能全部调入Cache,则当某些快被替换后,若又重新被访问,就会发生容量不命中.(2003)
    \item \emph{冲突不命中(Conflict Miss)}:在组相联或者直接映像Cache中,若太多的块映像到同一组(块)中,则会出现某个块被别的块替换,然后又被重新访问的情况,就会发生冲突不命中.
  \end{enumerate}
  \item 映像规则(2005)
  \begin{enumerate}
    \item \textbf{全相联映像(Fully Associative)}:把主存中任意一块放置到Cache中任意一个位置
    \item \textbf{直接映像(Direct Mapping)}:主存中每一块放置到Cache中唯一位置
    \item \textbf{组相联映像(Set Associative)}:主存中每一块放置到Cache中唯一一个组中任意位置
  \end{enumerate}
  \item 预取方式
  \begin{enumerate}
    \item \emph{寄存器预取}:把数据取到寄存器中
    \item \emph{Cache预取}:把数据取到Cache中
    \item \emph{故障性预取}:预取时,若出现\blank{虚地址故障}或\blank{违反保护权限},就会发生异常
    \item \textbf{非故障性预取(非绑定预取,nonbinding)}:当出现虚地址故障或违反保护权限时,不发生异常,而是放弃预取,转为空操作.非绑定预取能够返回\blank{最新数据值},并且保证对数据实际的存储器访问的是最新的数据项(2008、2009)
  \end{enumerate}
  \item TLB是一个专用的(\emph{\underline{高速缓存部件}}),用于存放近期经常使用的(\emph{\underline{页表项}}),其内容是页表部分内容的一个(\emph{\underline{副本}}).(2007、2012)
\end{enumerate}
\subsection{简答}
\begin{enumerate}
  \item \emph{简述两级Cache的工作原理:}(2001)
  
  答：在原有Cache和存储器之间增加另一级Cache，构成两级Cache，这就可以把第一级Cache做的足够小，使其能够和快速CPU的时钟周期相匹配；同时把第二级Cache做的足够大，使其能捕获更多本来需要到主存去的访问，降低实际不命中开销，克服CPU和主存之间的性能差距，使存储器和CPU性能匹配。

  \item \emph{简述TLB的工作原理}(2001):
  
  TLB用于存放近期经常使用的页表项，其内容是页表部分内容的一个副本。进行地址转换时，直接查找TLB，只有在TLB不命中时，才需要访问内存中的页表，也成为块表或地址变换缓冲器，是一种能够实现快速地址变换的技术。
  
  \item \emph{cache-主存 与 主存-辅存层次的区别}:(2004)
  \begin{table}[!hbp]
    \centering
    \begin{tabular}{c|c|c}
      \hline
      &Cache-主存层次&主存-辅存层次 \\
      \hline  
      目的&为了弥补主存速度不足&为了弥补主存容量不足\\
      \hline
      存储管理的实现&全部由硬件实现&主要由软件实现\\
      \hline
      访问速度的比值(第一级比第二级)&几比一&几万比一\\
      \hline
      典型块大小&几十个到几百个字节&几千个以上字节\\
      \hline
      CPU对第二级的访问&可直接访问&均通过第一级\\
      \hline
      不命中时CPU是否切换&不切换&切换到其他进程\\
      \hline
    \end{tabular}  
  \end{table}
  
        
  \item \emph{减少Cache失效开销的策略}(2002):

  采用两级Cache；读不命中优先于写；写缓冲合并；请求字处理技术；非阻塞Cache
  \item 减少Cache命中时间的策略:
  
  容量小且结构简单的Cache；虚拟Cache；访问流水化；多体Cache；路预测；Trace Cache；
  \item 降低Cache不命中率的策略：
  
  调节Cache块大小，增加Cache容量；提高相联度；采用Victim Cache；采用伪相联Cache；硬件预取；编译器控制的预取；编译优化；
\end{enumerate}

\newpage
\section{互连网络}
\subsection{名词解释/填空}
\begin{enumerate}
  \item 在拓扑上,互连网络为输入和输出两组节点之间提供了一组\emph{\underline{互连}}或\emph{\underline{映像}}.
  \item \textbf{均匀混洗(shuffle)}: 输入左移一位；\textbf{超立方体路由}:特定为置反；设互联网的输入为$(x_{k-1},\cdots,x_1,x_0)$,则均匀混洗输出是y=\blank{$x_{k-2},\cdots,x_1,x_0,x_{k-1}$},超立方体输出是y=\blank{$x_{k-1},\cdots,\bar{x_j},\cdots,x_1,x_0$}。(2010)
  \item \emph{静态互连网络}:由点和点直接相连而成
  \item \emph{动态互连网络}:由\underline{\emph{开关通道}}实现,可以动态改变结构
  \item \emph{节点度}:与节点相连接的边的数目称为节点度,这里的边表示链路或通道,进入节点的通道数为入度,从节点出来的通道数为出度
  (\emph{节点度=入度+出度})(2008).
  \item \textbf{网络直径}:网络中任意两个节点间\blank{最短}路径长度的\blank{最大值}叫做(\emph{\underline{网络直径}}).(2002、2004、2006、2009、2010、2012、2014、2016、2017)
  \item \textbf{等分宽度}:将网络切成\blank{任意相等两半的各种切法中},沿切口的\blank{最小通道边数}称为等分带宽.(2009、2011、2013、2014、2015)
  \item 对于一个网络,如果从任何一个节点看,拓扑结构都一样,则称此网络为对称网络.
  \item \emph{路由}:在网络通信中对路径的选择与指定.
  \item \textbf{虚拟自适应}:将一个\blank{物理通道}分成几个\blank{虚拟的通道}，根据后续各虚拟通道的\blank{资源或网络}情况自适应选择后续通道。(2003、2007、2012、2015)
  \item \textbf{虫孔路由(Worm hole)}:把信息包分成(\emph{\underline{小片}}),片头带(\emph{\underline{目的地址}}),所有片以不可分离的(\emph{\underline{流水方式}})通过片缓冲区进行传输路由 .(2001、2004、2007、2012)
\end{enumerate}
\subsection{简答题}
\begin{enumerate}
  \item \emph{简单比较动态网络中总线、多级网络、交叉开关的特点:}(2003)
  \begin{itemize}
    \item 总线结构：系统总线在处理机、I/O子系统、存储模块或辅助存储设备之间提供了一条公用通信通路。主动设备或主设备产生访问存储器的请求，被动设备或从设备则响应请求。在多个请求情况下，总线仲裁分配总线的使用权。公用总线是在分时基础上工作的。
    \item 多级网络：多级网络可用于构造大型多处理机系统。每一级都采用了多个开关，相邻级开关之间都有固定的级间链接。主要有点是采用模块结构，可扩展性较好，然而其时延随着网络的级数二上升。
    \item 交叉开关：它把N台处理机和M个存储器连接起来，网络中的每个交叉点是一个允许任何一台处理机和任何一个存储器连接的开关。属于无阻塞置换网络。交叉开关的硬件复杂性较高，但交叉开关的带宽和路由性能最好。
  \end{itemize}
  
\end{enumerate}

\newpage
\section{多处理机}
\subsection{名词解释/填空}
\begin{enumerate}
  \item \textbf{Home结点(宿主结点)}:是指存放\blank{需要访问}的\blank{存储单元}及\blank{相应的目录项}所在的结点.(2008、2009、2016)
  \item \emph{本地结点(local node)}:发出\blank{访问请求}的结点.
  \item \emph{远程结点(remote node)}:拥有\blank{被访问存储块副本}的结点.
  \item \emph{拥有者(owner)}是指拥有唯一的\blank{Cache块副本}的处理器.(2008)
  \item \textbf{栅栏同步}:栅栏强制所有的到达该栅栏的进程进行等待,直到(\emph{\underline{全部的进程}})到达栅栏,然后(\emph{\underline{释放}})全部的进程,从而形成同步.(2003、2007、2013、2016)
  \item 同时多线程(Simultaneous Multi Threading, SMT)是同时实现(\emph{\underline{指令级}})和线程级的并行,每拍有(\emph{\underline{多个指令槽}}),可以安排多个线程的(\emph{\underline{多条指令}})同时流出。(2005、2009、2011、2014、2015)
  \item 基本硬件原语:\emph{原子交换(Atomic Exchange)}将一个存储单元的值和一个寄存器的值进行交换；\emph{测试并置定(test\li and\li set)}先测试一个存储单元的值,如果符合条件则修改其值；\emph{读取并加1(fetch\li and\li increment)}返回存储单元的值并自动增加该值;\emph{指令对LL/SC},从第二条指令的返回值判断该指令执行是否成功,这两条指令之间不能插入其他对存储单元进行操作的其他指令.
  \item 大规模机器的同步方法:(2010、2012、2013、2014、2017)
  \begin{enumerate}
    \item 硬件方法：
    \begin{itemize}
      \item \textbf{排队锁}:通过硬件向量等方式进行排队和同步控制。
      \item \textbf{硬件原语}:引进一种原语(可以是Fetch\li and\li increment)减少栅栏技术时所需的时间，从而减小串行形成的瓶颈。
    \end{itemize}
    \item 软件方法:
    \begin{itemize}
      \item \textbf{延迟等待旋转锁}：加锁失败时，延迟的时间指数增大;
      \item \textbf{排队锁}:用数组将要进行同步的进程排队，按照排序进行同步操作；
      \item \textbf{组合树栅栏}:通过组合树(Combining Tree)减少栅栏中进程读取release标志形成的冲突。
    \end{itemize}
  \end{enumerate}
  \item MIMD计算机分类、存储器系统结构
  \begin{enumerate}
    \item \emph{集中式共享存储器结构(Centralized Shared-Memory Architecture)}:处理器较少，共享一个集中式的物理存储器。因为主存单一，且对各处理器的关系是对称的，所以称其为\textbf{对称式共享存储器多处理机(Symmetric shared-memory Multi processor, SMP)}，因此也称为\textbf{UMA(Uniform Memory Access)}结构。
    \item \emph{分布式存储器多处理机}:存储器在物理上是分布的，支持大规模的多处理机系统，具有两种存储器系统结构和处理器通信方式：
    \begin{itemize}
      \item 把物理上分离的所有存储器进行统一的\blank{共享逻辑空间}进行编址，任何处理器都可访问任何存储单元，这类系统称为\textbf{分布式共享存储器系统(Distributed Shared-Memory, DSM)}，此处共享是\blank{地址空间上}的共享，不具有集中的存储器，也被称为\textbf{NUMA}，，这是因为其\blank{访存时间}取决于\blank{数据}在存储器中的\blank{存放位置}。(2011、2013、2014、2015、2017)
      \item 把每个结点中存储器编址为一个\blank{独立的地址空间}，不同结点地址空间独立，每个结点中存储器只能有本地处理器进行访问，远程处理器不能对其进行直接访问，这种计算机系统多以\blank{机群}形式存在。
    \end{itemize}
  \end{enumerate}
\end{enumerate}
\subsection{简单题}
\begin{enumerate}
  \item \emph{共享主存多处理结构(UMA)及其特点:}(2002)
  \begin{figure}[htbp]
    \caption{共享主存多处理器结构}
    \centering
    \includegraphics[height=0.3\textwidth]{figures/uma.png}
  \end{figure}
  
  特点：处理器数目较少，可通过大容量的Cache和总线互联使各处理器共享一个单独的物理存储器；只有一个单独的主存，而且这个主存对于各处理的关系是对称的，从各处理器访问它的时间相同；由于增加处理器会使可能的数据通路数量大大增加，从而导致可用带宽减小，因此UMA可扩展性差。
  \item 分布式存储器结构及其特点：
  \begin{figure}[htbp]
    \caption{分布式存储器结构}
    \centering
    \includegraphics[height=0.3\textwidth]{figures/fenbushi.png}
  \end{figure}
  
  特点：可以支持较大数目的处理器，系统中每个结点包含了处理器、存储器、I/O以及互联网络的接口。分布式存储器结构需要高带宽的互联网络。分布式存储器结构带来的好处包括，第一如果大多数的访问是针对本节点的局部处理器，则可降低对存储器和互联网络的带宽要求，第二对局部存储器的访问延迟低。分布式存储器结构最主要的缺点是处理器之间的通信较为复杂。
  \item 多处理Cache的一致性及其解决方案:
  
  如果允许共享数据进入Cache，就可能出现多个处理器的Cache中都有同一存储快的副本的情况，当其中某个处理器对其Cache中的数据就行修改后，就会使其Cache中的数据与其他Cache中的数据不一致。这就是多处理机的Cache一致性(Cache coherence)。
  
  保持一致性要求的两种协议模式：
  \begin{itemize}
    \item 写作废协议(Write Invalidate)：在处理器写某个数据项之前保证它对该数据项有唯一的访问权，具体做法是在进行写入之前，把所有其他Cache中的副本全部作废；
    \item 写更新协议(Write Update):在一个处理器写某个数据项时，通过广播使其他Cache中所有对应的数据项副本进行更新。
  \end{itemize}
  写更新协议和写作废协议的性能差别来自三个方面:
  \begin{itemize}
    \item 对同一数据的多个写而中间无读操作的情况，写更新协议需要进行多次写广播操作，而写作废协议只需一次作废操作；
    \item 对同一块中多个字进行写，写更新协议对每个字的写均要进行一次广播，而在写作废协议下仅对本快的第一次写时进行作废操作即可。写作废是针对Cahce块进行操作的，写更新是针对字(或字节)进行操作的；
    \item 从一个处理器写到另一个处理器读之间的延迟通常在写更新模式中较低，因为它在写数据是马上更新了相应的其他Cache中的内容(假设读的处理器Cahce中有此数据)，而在写作废协议中，需要读一个新的备份。
  \end{itemize}
  
  \item 存储器一致的三个条件:
  \begin{itemize}
    \item 处理器P对X单元进行一次写之后又对X进行读，读和写之间没有其他处理器对X单元进行写，则读的返回值总是写进的值；
    \item 一个处理器对X单元进行写之后，另一个处理器对X单元进行读，读和写之间无其他写，则读X单元的返回值应为写进的值；
    \item 对同一单元的写是顺序化的，即任意两个处理器对同一单元的两次写，从处理器看来顺序是相同的。
  \end{itemize}
  \item \emph{监听协议的工作原理:}(2003、2005)
  
  每个Cache中除了包含物理存储器中块的数据备份之外，也保存着各个块的共享状态信息。Cache通常连接在共享存储器的总线上，各个Cache控制器通过监听总线来判断他们是否有总线上请求的数据块。
  
  实现监听协议的关键有三个方面：
  \begin{itemize}
    \item 处理器之间通过一个可以实现广播的互连机制相连，通常采用的是总线；
    \item 当Cache响应本地处理器的访问时，如果它涉及全局操作，其Cache控制器就要在获得总线的控制权后，在总线上发出相应的消息。
    \item 所有的处理器都一直在监听总线，它们检测总线上的地址在它们的Cache中是否有副本，若有，则响应消息，并进行相应的操作。
  \end{itemize}
  获取总线控制权的顺序性保证了写操作的串行化。
  
  Cache发送到总线上的消息事务主要有以下三种：读不命中、写不命中、作废

  其中，“写不命中”和“读不命中”表示本地CPU对Cache进行读访问和写访问不命中，这时都需要通过总线找到相应数据块的最新副本，然后调入本地Cache。对于写直达Cache，数据最新值由存储器提供，对于写回Cache，若数据最新值在某个处理器的Cahce中，则由该处理Cache向请求方提供该快，并停止由读不命中和写不命中引发的对存储器的访问；“作废”用来通知其他处理器作废相应的副本。
  
  Cache本来就有的标识用来实现对总线监听，通过把总线上的地址和Cache内的标识进行比较，就能找到相应的Cache块；
  
  通过每个块的有效位可以实现作废机制，当要作废一个块时，只需将其有效位置为无效即可；
  
  为了分辨某个数块是否共享，通过给每个Cache块增设一个共享为来表示该快是处于共享状态还是独占状态。
  
  在监听协议中假设操作具有原子性，即操作进行过程中不能被打断。
  
  在一个基于总线的集中共享多处理中，监听协议下Cahce块有以下三种状态，每个数据块的状态只能为其中一种：
  \begin{itemize}
    \item 共享:在一个或多个处理器上具有该快的副本，且主存中的值为最新值；
    \item 未缓冲:所有处理器中的Cache都没有该快的副本；
    \item 独占:仅有一个处理器上由此快的副本，且已对此块进行了写操作，而主存中的数据块仍为旧的。
  \end{itemize}
  响应CPU请求的Cache状态转换如左图所示，处理机相应来自总线请求的状态转换如右图所示：
  \begin{figure}[htbp]
    \caption{监听协议状态转换图}
    \centering
    \includegraphics[height=0.4\textwidth]{figures/listenprotocol.png}
  \end{figure}
  
  写直达Cache与写回Cache最大的区别在于，本地处理器不需要读取另一个处理器的Cache块。从而在写直达协议中不在提供硬件在读失效或写失效是将被替换的块强制写回内存，也不再因访问其他Cache而中断处理器访问。主存在在CPU每次写Cache时都会更新，所以在处理器产生读失效后就会直接访问主存。在写直达Cache中，共享或独占的Cache块都与主存保持一致性。
  
  \item 目录协议的工作原理：
  
  物理存储器中共享数据块的状态及相关信息均被保存在一个称为目录的地方。它记录着可以进入Cache的每个数据块的访问状态、该快在各个处理器的共享状态以及是否修改过等信息。
  
  目录协议通常采用位向量的方法记录那些Cache中有副本；目录协议根据位向量中的信息和当前要进行的操作，依次对相应的Cache发送控制消息，并完成对目录项信息的修改。
  
  目录协议中，存储块的状态有三种：
  \begin{itemize}
    \item 未缓冲：该块尚未调入Cache，所有处理器中都没有这个块的副本；
    \item 共享：一个或多个处理机上有该快的副本，且这些副本与存储器中的该快相同；
    \item 独占：仅有一个处理机中有该块的副本，且该处理机已对其进行了写操作，所以存储器中该块的数据已经过时。
  \end{itemize}
  在目录协议中，本地结点是发出请求的结点，主节点是指包含所访问的存储单元及其目录项的结点，远程结点是拥有相应存储快副本的结点。
  
  结点间传递的消息类型如下表所示：
  \begin{table}[!hbp]
    \centering
    \caption{目录协议中结点间传递的消息类型}
    \begin{tabular}{llllp{6cm}} 
      \hline
      消息类型&来源&目标&消息内容&消息的功能 \\
      \hline
      读失效&本地结点&主结点&P，A&结点P读取地址A不命中，请求数据并将P加入共享集 \\
      \hline
      写失效&本地结点&主结点&P，A&结点P写地址A不命中，请求数据并使P成为独占者\\
      \hline
      作废&本地结点&主结点&A&请求向所有包含地址A块的远程Cache发送作废请求\\
      \hline
      作废&主节点&远程结点&A&作废远程Cache中包含地址A的数据块\\
      \hline
      取数据&主节点&远程结点&A&从远程Cache中取出包含地址A的数据块，并送至主节点，把远程Cahce中该块的状态设为共享\\
      \hline
      取数据并作废&主节点&远程结点&A&从远程Cache中取出包含地址A的数据块，送至主节点，然后作废远程Cache的那个块\\
      \hline
      数据值应答&主节点&本地结点&D&主节点返回数据值\\
      \hline
      写回&远程结点&主节点&A，D&写回地址A的数据值\\
      \hline
    \end{tabular}
  \end{table}
  
  相应本地Cache CPU请求时Cache的状态转换图如左图所示，远程结点中Cache块响应来自宿主结点的请求的状态转换图如右图所示。目录可能接收到三种不同的请求：写失效、读失效、或数据写回。下图是Cache在各个状态下所接收到的请求和进行的响应操作。
  
  \begin{figure}[htbp]
    \centering
    \includegraphics[height=0.7\textwidth]{figures/content.png}
  \end{figure}
  

  \item 监听协议与目录协议的对比:
  监听协议的优缺点：当Cache发生不命中时，在总线上广播相应的消息，容易实现、成本较低，然而当系统规模变大时，大量的总线广播会使得总线变成系统的瓶颈。
  
  \item LL/SC同步原语的原理：
  
  LL指令称为\emph{链接载入}或\emph{锁定载入}指令，SC指令称为\emph{条件存储}指令。对于链接载入指令所指定的存储器位置，如果其内容在对同一位置执行条件存储之前发生了改变，那么条件存储指令就会执行失败。如果两条指令之间进行了上下文切换(不能有的处理器的指令在链接载入和条件存储指令之间执行)，那么条件存储也会执行失败。
  
  \item \emph{栅栏同步}:(2004)
  
  栅栏同步强制所有到达该栅栏的进程进行等待，直到全部的进程到达栅栏，然后释放全部的进程，从而形成同步。栅栏的典型实现是用两个旋转锁，一个用来保护一个计数器，另一个用来封锁进程直至最后一个进程到达栅栏。下面是一个典型的实现：
  \begin {lstlisting}[language=C] 
    lock(counterlock);
    if(counter==0)release=0;
    count=count+1;
    unlock(counterlock);
    if(count==total){
      count=0;
      release=1;
    }
    else{
      spin(release);
    }
  \end{lstlisting}
  
  假设所有进程在离开栅栏时，其中有一个进程还没有离开栅栏，即停留在旋转等待操作上，这是如果有新的进程有又到达了栅栏，而上一次循环的进程最后那个还没来得及离开栅栏，那么这个块进程会将release重新置为0，从而将慢进程捆在栅栏上，这样所有的进程都会处于无限等待状态，因为进程的总数达不到total。
  
  改进的办法是当进程离开栅栏是进行计数，在上次栅栏使用的所有进程离开前，不允许任何进程重用并初始化栅栏，这样会明显增加栅栏的延迟和竞争。
  另一种方法是sense$\li$reversing栅栏，每个进程均使用一个私有变量local$\li$sense，该变量初始化为1。下面是一个sense$\li$reversing的实现：
  \begin {lstlisting}[language=c]
    local_sense=!local_sense;
    lock(counterlock);
    counter++;
    unlock(counterlock);
    if(count==total){
      count=0;
      release=local_sense;
    }
    else{
      spin(release==local_sense);
    }
  \end{lstlisting}
  
  标准的栅栏同步中，如果单个处理器的通过时间(包括更新计数和释放锁)为C，那么N个处理器进行一次同步的所需要的时间为NC。
  
  \item \emph{比较同时多线程(Simultaneous Multithreading)、粗粒度多线程和细粒度多线程及其特点}:(2006)
  \begin{itemize}
    \item 细粒度多线程能够在指令之间进行线程切换，从而使多个线程交替执行。优点在于能够隐藏由于长时间或短时间停顿引起的吞吐率的缺失。主要缺点是降低了每个线程的执行速度，这是因为及时没有任何停顿的线程也不能连续执行，而且会因为其他线程指令的插入执行而被延迟。
    \item 粗粒度多线程的切换只发生时间较长的停顿出现时候。优点在于降低了线程的切换次数，不太会降低线程的执行速度。缺点在于减少吞吐率损失的能力有限，特别是对于较短的停顿来说更是如此。这是由于粗粒度多线程的流水线建立时间的开销造成的。
    \item 同时多线程是一种在多流出、动态调度的处理器上同时开发线程级并行性和指令级并行性的技术。通过寄存器重命名和动态调度，多个线程的指令可以在数据路径上混合执行。在同时多线程中，所有的发射槽在一个时钟周期内被多个线程共享，线程级并行和指令级并行被同时开发。
  \end{itemize}
  
  \item \emph{k组合树栅栏同步所需的时间}:(2005)
  
  k元组合树是多个请求在局部结合起来形成数的一种分级结构，局部组合的分支数量大大小于总的分支数量，因此组合树降低冲突的原因是将大冲突化解成为并行的多个小冲突。每个结点组合K个进程，提供一个单独的计数器和锁，因而在每个结点有k个进程进行竞争，当K个进程都到达树中，对应结点则进入父节点，然后递增父节点计数器，当父节点计数到达K时，置release标志。则所需的时间为$\lceil log_kN \rceil*kC$。
  
  \item \emph{宽松一致性模型、特点及其硬件支持}(2003、2006):
  宽松一致性模型的关键特点是允许乱序执行读取和写入操作，但是用同步操作来实施排序。同步程序的表现就像处理器具备顺序连贯性一样。松弛一致性在保证程序正确性前提下增加了指令执行的并行，所以采用松弛一致性模型的机器可以提高性能。根据消除的读取顺序的内容，可以将松弛一致性模型划分为四类：
  \begin{itemize}
    \item 消除$W\leftarrow R$顺序，完全存储排序模型。在硬件支持上为写缓冲的读旁路等。维护写的次序，能够允许处理机在其写的操作被所有别的处理机看到之前就继续进行读。
    \item 消除了$W\leftarrow W$顺序。得到部分存储排序模型。在硬件支持上为写的流水线或其他写并行等。允许非冲突写隐含地乱序进行。实现上，可以是写流水化或重叠，而不是强制一个操作必须在另一个之前结束，对同步操作扔需将写操作挂起，因为它引起写保护。
    \item 消除了$R\leftarrow R$，$R\leftarrow W$顺序。得到多种模型包括弱排序模型、释放连贯性模型。在硬件支持上为不封锁读。
  \end{itemize}
  
  \item \emph{时延隐藏技术}:(2001、2004)
  
  多处理系统采用了包括数据预取、相关性Cache、松弛一致性、多现场这几种时延隐藏技术。
  \begin{itemize}
    \item 数据预取：在数据使用之前就将其取到近处；
    \item 相关性Cache：减少对共享数据访问的竞争及时延；
    \item 松弛一致性：在保证程序正确性前提下增加指令执行的并行；
    \item 多现场：在产生时延时进行现场切换转而执行其他程序。
  \end{itemize}
  
\end{enumerate}

\end{document}
